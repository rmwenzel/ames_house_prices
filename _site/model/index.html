<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Predictive modeling &middot; Ames Housing Data
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/ames_house_prices/public/css/poole.css">
  <link rel="stylesheet" href="/ames_house_prices/public/css/syntax.css">
  <link rel="stylesheet" href="/ames_house_prices/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/ames_house_prices/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/ames_house_prices/public/favicon.ico">
  --->

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!--- KaTeX --->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">

  <nav class="sidebar-nav">

    <a class="sidebar-nav-item" href="/ames_house_prices/process/">Process</a>
    <a class="sidebar-nav-item" href="/ames_house_prices/explore/">Explore</a>
    <a class="sidebar-nav-item active" href="/ames_house_prices/model/">Model</a>

  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2020.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/ames_house_prices/" title="Home">Ames Housing Data</a>
            <small>Processing, analysis and predictive modeling</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="page">
  <h1 class="page-title">Predictive modeling</h1>
  	
<p>In a previous notebook we <a href="/ames_house_prices/process/">processed and cleaned</a> the Ames dataset, and in another we <a href="/ames_house_prices/explore/">explored the data</a>.</p>

<p>In this notebook, we’ll model and predict <code class="language-plaintext highlighter-rouge">SalePrice</code>. First we’ll do a little feature selection and engineering to create a few different versions of the data for modeling. Then we’ll compare the prediction performance of some appropriate models on these versions, select a subset of these versions and models for fine-tuning, ensemble them to maximize predictive generalizablity, and test them by submitting to Kaggle.</p>

<h2 id="contents">Contents</h2>

<ul>
  <li><a href="#setup">Setup</a></li>
  <li><a href="#load-and-prepare-data">Load and prepare data</a></li>
  <li><a href="#feature-selection-and-engineering">Feature selection and engineering</a></li>
  <li><a href="#model-selection-and-tuning">Model selection and tuning</a>
    <ul>
      <li><a href="#create-modeling-datasets">Create modeling datasets</a></li>
      <li><a href="#compare-default-models-for-baseline">Compare default models for baseline</a></li>
      <li><a href="#tune-best-individual-models">Tune best individual models</a>
        <ul>
          <li><a href="#ridge-regression">Ridge Regression</a></li>
          <li><a href="#bayesian-ridge-regression">Bayesian Ridge Regression</a></li>
          <li><a href="#partial-least-squares">Partial Least Squares</a></li>
          <li><a href="#support-vector-machine">Support Vector Machine</a></li>
          <li><a href="#gradient-boosted-trees">Gradient Boosted Trees</a></li>
          <li><a href="#compare-tuned-models-and-save-parameters">Compare tuned models and save parameters</a></li>
        </ul>
      </li>
      <li><a href="#tune-ensembles">Tune Ensembles</a>
        <ul>
          <li><a href="#voting">Voting</a>
            <ul>
              <li><a href="#default-base-and-uniform-weights">Default base and uniform weights</a></li>
              <li><a href="#pretuned-base-and-uniform-weights">Pretuned base and uniform weights</a></li>
              <li><a href="#fully-tuned-voter">Fully tuned voter</a></li>
            </ul>
          </li>
          <li><a href="#stacking">Stacking</a>
            <ul>
              <li><a href="#default-base-and-meta">Default base and meta</a></li>
              <li><a href="#pretuned-base-and-meta">Pretuned base and meta</a></li>
              <li><a href="#fully-tuned-stacks">Fully tuned stacks</a>
                <ul>
                  <li><a href="#ridge-meta">Ridge Regression meta</a></li>
                  <li><a href="#svr-meta">Support Vector Machine meta</a></li>
                  <li><a href="#gradient-boosted-tree-meta">Gradient Boosted Tree meta</a></li>
                </ul>
              </li>
              <li><a href="#compare-ensembles">Compare ensembles</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#predict-and-evaluate">Predict and Evaluate</a></li>
</ul>

<h2 id="setup">Setup</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">hyperopt.hp</span> <span class="k">as</span> <span class="n">hp</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">BayesianRidge</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_decomposition</span> <span class="kn">import</span> <span class="n">PLSRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span><span class="p">,</span> <span class="n">ExtraTreeRegressor</span>
<span class="kn">from</span> <span class="nn">hyperopt.pyll</span> <span class="kn">import</span> <span class="n">scope</span> <span class="k">as</span> <span class="n">ho_scope</span>

<span class="c1"># add parent directory for importing custom classes
</span><span class="n">pardir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">pardir</span><span class="p">))</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pardir</span><span class="p">)</span>

<span class="c1"># custom classes and helpers
</span><span class="kn">from</span> <span class="nn">codes.process</span> <span class="kn">import</span> <span class="n">DataDescription</span><span class="p">,</span> <span class="n">HPDataFramePlus</span><span class="p">,</span> <span class="n">DataPlus</span>
<span class="kn">from</span> <span class="nn">codes.explore</span> <span class="kn">import</span> <span class="n">load_datasets</span><span class="p">,</span> <span class="n">plot_cont_dists</span>
<span class="kn">from</span> <span class="nn">codes.model</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s">'seaborn-white'</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">'white'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="load-and-prepare-data">Load and prepare data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hp_data</span> <span class="o">=</span> <span class="n">load_datasets</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="s">'../data'</span><span class="p">,</span> <span class="n">file_names</span><span class="o">=</span><span class="p">[</span><span class="s">'clean.csv'</span><span class="p">])</span>
<span class="n">clean</span> <span class="o">=</span> <span class="n">hp_data</span><span class="o">.</span><span class="n">dfs</span><span class="p">[</span><span class="s">'clean'</span><span class="p">]</span>
</code></pre></div></div>

<p>The dataset <code class="language-plaintext highlighter-rouge">clean</code> was <a href="process.ipynb/#Processing-and-cleaning-the-Ames-housing-dataset">created in a previous notebook</a>. It is the original dataset with some problematic variables and observations dropped and missing values imputed. We’ll use it to create our modeling data</p>

<h2 id="feature-selection-and-engineering">Feature selection and engineering</h2>

<p>We’ll use the results of <a href="explore.ipynb/#Exploratory-analysis-of-Ames-housing-dataset">our exploratory analysis</a> to suggest variables that can be altered, combined, or eliminated in the hopes of improving predictive models. We’ll create a few new datasets in the process. In the end we’ll have four versions of the data for modeling</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">clean</code>: original dataset with problematic features and observations dropped and missing values imputed.</li>
  <li><code class="language-plaintext highlighter-rouge">drop</code>: <code class="language-plaintext highlighter-rouge">clean</code> dataset with some old features dropped</li>
  <li><code class="language-plaintext highlighter-rouge">clean_edit</code>: <code class="language-plaintext highlighter-rouge">clean</code> dataset with some feature values combined and some new features added</li>
  <li><code class="language-plaintext highlighter-rouge">drop_edit</code>: <code class="language-plaintext highlighter-rouge">drop</code> dataset with the same feature values combined and same new features added.</li>
</ul>

<h3 id="drop-some-features">Drop some features</h3>

<p>Here are variables we’ll drop (and the reasons for dropping):</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Heating</code>, <code class="language-plaintext highlighter-rouge">RoofMatl</code>, <code class="language-plaintext highlighter-rouge">Condition2</code>, <code class="language-plaintext highlighter-rouge">Street</code> (extremely unbalanced distributions and very low dependence with <code class="language-plaintext highlighter-rouge">SalePrice</code> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>⪆</mo><mn>0.99</mn></mrow><annotation encoding="application/x-tex">D \gtrapprox 0.99</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.01166em;vertical-align:-0.25583em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⪆</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">9</span></span></span></span>))</li>
  <li><code class="language-plaintext highlighter-rouge">Exterior2nd</code> (redundant with <code class="language-plaintext highlighter-rouge">Exterior1st</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">HouseStyle</code> (redundant with <code class="language-plaintext highlighter-rouge">MSSubclass</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">Utilities</code> (extremely unbalanced distribution and very low dependence with response)</li>
  <li><code class="language-plaintext highlighter-rouge">PoolQC</code> (extremely unbalanced distribution and redundant with <code class="language-plaintext highlighter-rouge">PoolArea</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">1stFlrSF</code> and <code class="language-plaintext highlighter-rouge">TotalBsmtSF</code> (high dependence with <code class="language-plaintext highlighter-rouge">GrLivArea</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">GarageYrBlt</code> (high dependence with <code class="language-plaintext highlighter-rouge">YearBuilt</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">PoolArea</code>, <code class="language-plaintext highlighter-rouge">MiscVal</code>, <code class="language-plaintext highlighter-rouge">3SsnPorch</code>, <code class="language-plaintext highlighter-rouge">ScreenPorch</code>, <code class="language-plaintext highlighter-rouge">BsmtFinSF2</code> (extremely peaked distributions and very low dependence with <code class="language-plaintext highlighter-rouge">SalePrice</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">LowQualFinSF</code> (extremely peaked distribution and redundant with ordinal quality measures such as <code class="language-plaintext highlighter-rouge">OverallQual</code>)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Heating'</span><span class="p">,</span> <span class="s">'RoofMatl'</span><span class="p">,</span> <span class="s">'Condition2'</span><span class="p">,</span> <span class="s">'Street'</span><span class="p">,</span> <span class="s">'Exterior2nd'</span><span class="p">,</span> <span class="s">'HouseStyle'</span><span class="p">,</span> 
             <span class="s">'Utilities'</span><span class="p">,</span> <span class="s">'PoolQC'</span><span class="p">,</span> <span class="s">'1stFlrSF'</span><span class="p">,</span> <span class="s">'TotalBsmtSF'</span><span class="p">,</span> <span class="s">'GarageYrBlt'</span><span class="p">,</span> <span class="s">'PoolArea'</span><span class="p">,</span> <span class="s">'MiscVal'</span><span class="p">,</span>
             <span class="s">'3SsnPorch'</span><span class="p">,</span> <span class="s">'ScreenPorch'</span><span class="p">,</span> <span class="s">'BsmtFinSF2'</span><span class="p">,</span> <span class="s">'LowQualFinSF'</span><span class="p">]</span>
<span class="n">drop</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">drop</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">drop</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">drop_cols</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'LotShape',
       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',
       'BldgType', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',
       'RoofStyle', 'Exterior1st', 'MasVnrType', 'MasVnrArea', 'ExterQual',
       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',
       'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtUnfSF', 'HeatingQC',
       'CentralAir', 'Electrical', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath',
       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',
       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces',
       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCars', 'GarageArea',
       'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', 'Fence', 'MoSold', 'YrSold', 'SaleType',
       'SaleCondition', 'SalePrice'],
      dtype='object')
</code></pre></div></div>

<h3 id="combine-values-and-create-new-variables">Combine values and create new variables</h3>

<p>Some discrete variables had very small counts for some values (this could be seen as horizontal lines corresponding to those values in the violin plots for <a href="#Relationship-between-categoricals-and-SalePrice">categorical</a> and <a href="#Relationship-between-ordinals-and-SalePrice">ordinal</a> variables.</p>

<p>First we’ll look at categorical variables</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cats_data</span> <span class="o">=</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s">'category'</span><span class="p">)</span>
<span class="n">cats_data</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['MSSubClass', 'MSZoning', 'Street', 'LandContour', 'LotConfig',
       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'Foundation', 'Heating', 'CentralAir', 'Electrical', 'GarageType',
       'SaleType', 'SaleCondition'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># print variables with less than 5 observations for any value
</span><span class="n">small_val_count_cat_cols</span> <span class="o">=</span> <span class="n">print_small_val_counts</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cats_data</span><span class="p">,</span> <span class="n">val_count_threshold</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20     1078
60      573
50      287
120     182
30      139
70      128
160     128
80      118
90      109
190      61
85       48
75       23
45       18
180      17
40        6
150       1
Name: MSSubClass, dtype: int64

Norm      2887
Feedr       13
Artery       5
PosA         4
PosN         3
RRNn         2
RRAn         1
RRAe         1
Name: Condition2, dtype: int64

Gable      2310
Hip         549
Gambrel      22
Flat         19
Mansard      11
Shed          5
Name: RoofStyle, dtype: int64

CompShg    2875
Tar&amp;Grv      22
WdShake       9
WdShngl       7
Roll          1
Metal         1
Membran       1
Name: RoofMatl, dtype: int64

VinylSd    1026
MetalSd     450
HdBoard     442
Wd Sdng     411
Plywood     220
CemntBd     125
BrkFace      87
WdShing      56
AsbShng      44
Stucco       42
BrkComm       6
Stone         2
CBlock        2
AsphShn       2
ImStucc       1
Name: Exterior1st, dtype: int64

VinylSd    1015
MetalSd     447
HdBoard     406
Wd Sdng     391
Plywood     269
CmentBd     125
Wd Shng      81
BrkFace      47
Stucco       46
AsbShng      38
Brk Cmn      22
ImStucc      15
Stone         6
AsphShn       4
CBlock        3
Other         1
Name: Exterior2nd, dtype: int64

None       1761
BrkFace     945
Stone       205
BrkCmn        5
Name: MasVnrType, dtype: int64

PConc     1306
CBlock    1234
BrkTil     311
Slab        49
Stone       11
Wood         5
Name: Foundation, dtype: int64

GasA     2871
GasW       27
Grav        9
Wall        6
OthW        2
Floor       1
Name: Heating, dtype: int64

SBrkr    2669
FuseA     188
FuseF      50
FuseP       8
Mix         1
Name: Electrical, dtype: int64

WD       2525
New       237
COD        87
ConLD      26
CWD        12
ConLI       9
ConLw       8
Oth         7
Con         5
Name: SaleType, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">desc</span> <span class="o">=</span> <span class="n">DataDescription</span><span class="p">(</span><span class="s">'../data/data_description.txt'</span><span class="p">)</span>
<span class="n">clean</span><span class="o">.</span><span class="n">desc</span> <span class="o">=</span> <span class="n">desc</span>
<span class="n">clean</span><span class="o">.</span><span class="n">print_desc</span><span class="p">(</span><span class="n">small_val_count_cat_cols</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MSSubClass: Identifies the type of dwelling involved in the sale.

	 20 - 1-STORY 1946 &amp; NEWER ALL STYLES
	 30 - 1-STORY 1945 &amp; OLDER
	 40 - 1-STORY W/FINISHED ATTIC ALL AGES
	 45 - 1-1/2 STORY - UNFINISHED ALL AGES
	 50 - 1-1/2 STORY FINISHED ALL AGES
	 60 - 2-STORY 1946 &amp; NEWER
	 70 - 2-STORY 1945 &amp; OLDER
	 75 - 2-1/2 STORY ALL AGES
	 80 - SPLIT OR MULTI-LEVEL
	 85 - SPLIT FOYER
	 90 - DUPLEX - ALL STYLES AND AGES
	 120 - 1-STORY PUD (Planned Unit Development) - 1946 &amp; NEWER
	 150 - 1-1/2 STORY PUD - ALL AGES
	 160 - 2-STORY PUD - 1946 &amp; NEWER
	 180 - PUD - MULTILEVEL - INCL SPLIT LEV/FOYER
	 190 - 2 FAMILY CONVERSION - ALL STYLES AND AGES


Condition2: Proximity to various conditions (if more than one is present)

	 Artery - Adjacent to arterial street
	 Feedr - Adjacent to feeder street
	 Norm - Normal
	 RRNn - Within 200' of North-South Railroad
	 RRAn - Adjacent to North-South Railroad
	 PosN - Near positive off-site feature--park, greenbelt, etc.
	 PosA - Adjacent to postive off-site feature
	 RRNe - Within 200' of East-West Railroad
	 RRAe - Adjacent to East-West Railroad


RoofStyle: Type of roof

	 Flat - Flat
	 Gable - Gable
	 Gambrel - Gabrel (Barn)
	 Hip - Hip
	 Mansard - Mansard
	 Shed - Shed


RoofMatl: Roof material

	 ClyTile - Clay or Tile
	 CompShg - Standard (Composite) Shingle
	 Membran - Membrane
	 Metal - Metal
	 Roll - Roll
	 Tar&amp;Grv - Gravel &amp; Tar
	 WdShake - Wood Shakes
	 WdShngl - Wood Shingles


Exterior1st: Exterior covering on house

	 AsbShng - Asbestos Shingles
	 AsphShn - Asphalt Shingles
	 BrkComm - Brick Common
	 BrkFace - Brick Face
	 CBlock - Cinder Block
	 CemntBd - Cement Board
	 HdBoard - Hard Board
	 ImStucc - Imitation Stucco
	 MetalSd - Metal Siding
	 Other - Other
	 Plywood - Plywood
	 PreCast - PreCast
	 Stone - Stone
	 Stucco - Stucco
	 VinylSd - Vinyl Siding
	 Sdng - Wood Siding
	 WdShing - Wood Shingles


Exterior2nd: Exterior covering on house (if more than one material)

	 AsbShng - Asbestos Shingles
	 AsphShn - Asphalt Shingles
	 BrkComm - Brick Common
	 BrkFace - Brick Face
	 CBlock - Cinder Block
	 CemntBd - Cement Board
	 HdBoard - Hard Board
	 ImStucc - Imitation Stucco
	 MetalSd - Metal Siding
	 Other - Other
	 Plywood - Plywood
	 PreCast - PreCast
	 Stone - Stone
	 Stucco - Stucco
	 VinylSd - Vinyl Siding
	 Sdng - Wood Siding
	 WdShing - Wood Shingles


MasVnrType: Masonry veneer type

	 BrkCmn - Brick Common
	 BrkFace - Brick Face
	 CBlock - Cinder Block
	 None - None
	 Stone - Stone


Foundation: Type of foundation

	 BrkTil - Brick &amp; Tile
	 CBlock - Cinder Block
	 PConc - Poured Contrete
	 Slab - Slab
	 Stone - Stone
	 Wood - Wood


Heating: Type of heating

	 Floor - Floor Furnace
	 GasA - Gas forced warm air furnace
	 GasW - Gas hot water or steam heat
	 Grav - Gravity furnace
	 OthW - Hot water or steam heat other than gas
	 Wall - Wall furnace


Electrical: Electrical system

	 SBrkr - Standard Circuit Breakers &amp; Romex
	 FuseA - Fuse Box over 60 AMP and all Romex wiring (Average)
	 FuseF - 60 AMP Fuse Box and mostly Romex wiring (Fair)
	 FuseP - 60 AMP Fuse Box and mostly knob &amp; tube wiring (poor)
	 Mix - Mixed


SaleType: Type of sale

	 WD - Warranty Deed - Conventional
	 CWD - Warranty Deed - Cash
	 VWD - Warranty Deed - VA Loan
	 New - Home just constructed and sold
	 COD - Court Officer Deed/Estate
	 Con - Contract 15% Down payment regular terms
	 ConLw - Contract Low Down payment and low interest
	 ConLI - Contract Low Interest
	 ConLD - Contract Low Down
	 Oth - Other
</code></pre></div></div>

<p>We’ll perform the following combinations of categorical variable values:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">MSSubClass</code>: Change the single observation with value 150 to 50, the next most sensible value</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Condition2</code>: Merge <code class="language-plaintext highlighter-rouge">PosA</code>, <code class="language-plaintext highlighter-rouge">PosN</code>, <code class="language-plaintext highlighter-rouge">RRNn</code>, <code class="language-plaintext highlighter-rouge">RRAn</code>, and <code class="language-plaintext highlighter-rouge">RRAe</code> into a new value <code class="language-plaintext highlighter-rouge">Other</code></li>
  <li><code class="language-plaintext highlighter-rouge">RoofMatl</code>: Merge <code class="language-plaintext highlighter-rouge">WdShake</code>, <code class="language-plaintext highlighter-rouge">WdShingle</code> into a new value <code class="language-plaintext highlighter-rouge">Wood</code> and <code class="language-plaintext highlighter-rouge">Roll</code>, <code class="language-plaintext highlighter-rouge">Metal</code>, <code class="language-plaintext highlighter-rouge">Membran</code> into a new value <code class="language-plaintext highlighter-rouge">Other</code></li>
  <li><code class="language-plaintext highlighter-rouge">Exterior1st</code>, : Merge <code class="language-plaintext highlighter-rouge">BrkComm</code> into <code class="language-plaintext highlighter-rouge">BrkFace</code>, <code class="language-plaintext highlighter-rouge">AsphShn</code> into <code class="language-plaintext highlighter-rouge">AsbShng</code>, <code class="language-plaintext highlighter-rouge">ImStucc</code> into <code class="language-plaintext highlighter-rouge">Stucco</code> and  <code class="language-plaintext highlighter-rouge">Stone</code> and <code class="language-plaintext highlighter-rouge">CBlock</code> into a new value <code class="language-plaintext highlighter-rouge">Other</code></li>
  <li><code class="language-plaintext highlighter-rouge">Exterior2nd</code>: Merge <code class="language-plaintext highlighter-rouge">AsphShn</code> into <code class="language-plaintext highlighter-rouge">AsbShng</code> and <code class="language-plaintext highlighter-rouge">Stone</code> and <code class="language-plaintext highlighter-rouge">CBlock</code> into <code class="language-plaintext highlighter-rouge">Other</code></li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">Heating</code>: Merge <code class="language-plaintext highlighter-rouge">Wall</code>, <code class="language-plaintext highlighter-rouge">OthW</code>, and <code class="language-plaintext highlighter-rouge">Floor</code> into a new variable <code class="language-plaintext highlighter-rouge">Other</code></p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">MasVnrType</code>: Merge <code class="language-plaintext highlighter-rouge">BrkComm</code> in <code class="language-plaintext highlighter-rouge">BrkFace</code></li>
  <li><code class="language-plaintext highlighter-rouge">Electrical</code>: Merge <code class="language-plaintext highlighter-rouge">FuseA</code>, <code class="language-plaintext highlighter-rouge">FuseF</code>, <code class="language-plaintext highlighter-rouge">FuseP</code>, and <code class="language-plaintext highlighter-rouge">Mix</code> into a new value <code class="language-plaintext highlighter-rouge">NonStd</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># new dataframes
</span><span class="n">clean_edit</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">drop_edit</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drop</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># combine categorical variable values
</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">combine_cat_vars</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">combine_cat_vars</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drop</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<p>Now we’ll look at ordinal variables</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># print small value counts of ordinal variables
</span><span class="n">edit_ords_data</span> <span class="o">=</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s">'int64'</span><span class="p">)</span>
<span class="n">small_val_count_ord_cols</span> <span class="o">=</span> <span class="n">print_small_val_counts</span><span class="p">(</span><span class="n">edit_ords_data</span><span class="p">,</span> <span class="n">val_count_threshold</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3    2915
1       1
Name: Utilities, dtype: int64

5     825
6     731
7     600
8     342
4     225
9     107
3      40
10     29
2      13
1       4
Name: OverallQual, dtype: int64

3    2535
4     299
2      67
5      12
1       3
Name: ExterCond, dtype: int64

3    2603
4     122
2     104
0      82
1       5
Name: BsmtCond, dtype: int64

5    1490
3     857
4     474
2      92
1       3
Name: HeatingQC, dtype: int64

0    1707
1    1170
2      37
3       2
Name: BsmtFullBath, dtype: int64

0    2741
1     171
2       4
Name: BsmtHalfBath, dtype: int64

2    1529
1    1308
3      63
0      12
4       4
Name: FullBath, dtype: int64

3    1594
2     741
4     400
1     103
5      48
6      21
0       8
8       1
Name: BedroomAbvGr, dtype: int64

1    2782
2     129
0       3
3       2
Name: KitchenAbvGr, dtype: int64

2    1492
3    1150
4     203
1      70
0       1
Name: KitchenQual, dtype: int64

6     843
7     649
5     583
8     347
4     196
9     143
10     80
11     31
3      25
12     15
15      1
13      1
14      1
2       1
Name: TotRmsAbvGrd, dtype: int64

6    2717
3      70
5      64
2      35
4      19
1       9
0       2
Name: Functional, dtype: int64

0    1420
1    1267
2     218
3      10
4       1
Name: Fireplaces, dtype: int64

2    1593
1     776
3     373
0     157
4      16
5       1
Name: GarageCars, dtype: int64

3    2601
0     159
2     124
4      24
1       5
5       3
Name: GarageQual, dtype: int64

3    2651
0     159
2      74
4      15
1      14
5       3
Name: GarageCond, dtype: int64

0    2907
4       4
3       3
1       2
Name: PoolQC, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean</span><span class="o">.</span><span class="n">print_desc</span><span class="p">(</span><span class="n">small_val_count_ord_cols</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Utilities: Type of utilities available

	 AllPub - All public Utilities (E,G,W,&amp; S)
	 NoSewr - Electricity, Gas, and Water (Septic Tank)
	 NoSeWa - Electricity and Gas Only
	 ELO - Electricity only


OverallQual: Rates the overall material and finish of the house

	 10 - Very Excellent
	 9 - Excellent
	 8 - Very Good
	 7 - Good
	 6 - Above Average
	 5 - Average
	 4 - Below Average
	 3 - Fair
	 2 - Poor
	 1 - Very Poor


ExterCond: Evaluates the present condition of the material on the exterior

	 Ex - Excellent
	 Gd - Good
	 TA - Average/Typical
	 Fa - Fair
	 Po - Poor


BsmtCond: Evaluates the general condition of the basement

	 Ex - Excellent
	 Gd - Good
	 TA - Typical - slight dampness allowed
	 Fa - Fair - dampness or some cracking or settling
	 Po - Poor - Severe cracking, settling, or wetness
	 NA - No Basement


HeatingQC: Heating quality and condition

	 Ex - Excellent
	 Gd - Good
	 TA - Average/Typical
	 Fa - Fair
	 Po - Poor


BsmtFullBath: Basement full bathrooms



BsmtHalfBath: Basement half bathrooms



FullBath: Full bathrooms above grade



BedroomAbvGr: Bedrooms above grade (does NOT include basement bedrooms)



KitchenAbvGr: Kitchens above grade



KitchenQual: Kitchen quality

	 Ex - Excellent
	 Gd - Good
	 TA - Typical/Average
	 Fa - Fair
	 Po - Poor


TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)



Functional: Home functionality (Assume typical unless deductions are warranted)

	 Typ - Typical Functionality
	 Min1 - Minor Deductions 1
	 Min2 - Minor Deductions 2
	 Mod - Moderate Deductions
	 Maj1 - Major Deductions 1
	 Maj2 - Major Deductions 2
	 Sev - Severely Damaged
	 Sal - Salvage only


Fireplaces: Number of fireplaces



GarageCars: Size of garage in car capacity



GarageQual: Garage quality

	 Ex - Excellent
	 Gd - Good
	 TA - Typical/Average
	 Fa - Fair
	 Po - Poor
	 NA - No Garage


GarageCond: Garage condition

	 Ex - Excellent
	 Gd - Good
	 TA - Typical/Average
	 Fa - Fair
	 Po - Poor
	 NA - No Garage


PoolQC: Pool quality

	 Ex - Excellent
	 Gd - Good
	 TA - Average/Typical
	 Fa - Fair
	 NA - No Pool
</code></pre></div></div>

<p>Even though many ordinal variables have values with low counts, we’re less inclined to combine values because we lose ordering information. However we will drop <code class="language-plaintext highlighter-rouge">Utilities</code> from all data, since a binary variable with one observation for one value is essentially useless.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># drop extremely unbalanced binary variable
</span><span class="n">clean</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Utilities'</span><span class="p">])</span>
<span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Utilities'</span><span class="p">])</span>
</code></pre></div></div>

<p>We’ll also create some new variables:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Bath</code> = <code class="language-plaintext highlighter-rouge">HalfBath</code> + 2 * <code class="language-plaintext highlighter-rouge">FullBath</code> and drop
<code class="language-plaintext highlighter-rouge">HalfBath</code> and <code class="language-plaintext highlighter-rouge">FullBath</code></li>
  <li><code class="language-plaintext highlighter-rouge">BsmtBath</code> = <code class="language-plaintext highlighter-rouge">BsmtHalfBath</code> + 2 * <code class="language-plaintext highlighter-rouge">BsmtFullBath</code> and drop <code class="language-plaintext highlighter-rouge">BsmtHalfBath</code> and <code class="language-plaintext highlighter-rouge">BsmtFullBath</code></li>
  <li><code class="language-plaintext highlighter-rouge">AvgQual</code>, the average of <code class="language-plaintext highlighter-rouge">OverallQual</code>, <code class="language-plaintext highlighter-rouge">ExterQual</code>, <code class="language-plaintext highlighter-rouge">BsmtQual</code>, <code class="language-plaintext highlighter-rouge">HeatingQC</code>, <code class="language-plaintext highlighter-rouge">KitchenQual</code>, <code class="language-plaintext highlighter-rouge">FireplaceQu</code> and <code class="language-plaintext highlighter-rouge">GarageQual</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">AvgCond</code>, the average of <code class="language-plaintext highlighter-rouge">OverallCond</code>, <code class="language-plaintext highlighter-rouge">ExterCond</code>, <code class="language-plaintext highlighter-rouge">BsmtCond</code>, and <code class="language-plaintext highlighter-rouge">GarageCond</code></li>
  <li>Indicator variables <code class="language-plaintext highlighter-rouge">HasBsmt</code>, <code class="language-plaintext highlighter-rouge">HasFireplace</code>, <code class="language-plaintext highlighter-rouge">HasPool</code>, <code class="language-plaintext highlighter-rouge">HasGarage</code>, <code class="language-plaintext highlighter-rouge">HasFence</code></li>
</ul>

<p>Note the factor of 2 in the new bath variables is so full baths are twice the weight of half baths. Also note the new average quality and condition variables will be quantitative (<code class="language-plaintext highlighter-rouge">float64</code> dtype)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create new ordinal variables
</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">create_ord_vars</span><span class="p">(</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">create_ord_vars</span><span class="p">(</span><span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<p>Finally, we’ll look at quantitative variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">quants_data</span> <span class="o">=</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s">'float64'</span><span class="p">)</span>
<span class="n">quants_data</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',
       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',
       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea',
       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',
       'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice'],
      dtype='object')
</code></pre></div></div>

<p>We <a href="#Quantitative-variables">noted above</a> that many of these variables have high concentrations at zero. We’ll</p>

<ul>
  <li>Create indicator variables <code class="language-plaintext highlighter-rouge">Has2ndFlr</code>, <code class="language-plaintext highlighter-rouge">HasWoodDeck</code>, <code class="language-plaintext highlighter-rouge">HasPorch</code></li>
  <li>Create an overall area variable <code class="language-plaintext highlighter-rouge">OverallArea</code> = <code class="language-plaintext highlighter-rouge">LotArea</code> + <code class="language-plaintext highlighter-rouge">GrLivArea</code> + <code class="language-plaintext highlighter-rouge">GarageArea</code></li>
  <li>Create a lot variable <code class="language-plaintext highlighter-rouge">LotRatio</code> = <code class="language-plaintext highlighter-rouge">LotArea</code> / <code class="language-plaintext highlighter-rouge">LotFrontage</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create new quantiative variables
</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">create_quant_vars</span><span class="p">(</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">create_quant_vars</span><span class="p">(</span><span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="transform-skewed-quantitative-variables">Transform skewed quantitative variables</h3>

<p>We noted that many of the quantitative variables (including the response variable <code class="language-plaintext highlighter-rouge">SalePrice</code>)  had approximately logarithmic distributions, so we’ll apply a log transformation to these. Note that we expect this to improve the performance of some predictive modeling methods (e.g. linear regression) but to have little effect on other methods (e.g. tree-based methods).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">quants_data</span> <span class="o">=</span> <span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s">'float64'</span><span class="p">)</span>
<span class="n">quants_data</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',
       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',
       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea',
       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',
       'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice', 'AvgQual', 'AvgCond',
       'OverallArea', 'LotRatio'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># inspect distributions of quantitatives including new ones
</span><span class="n">plot_cont_dists</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">quants_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'SalePrice'</span><span class="p">]),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_34_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># find minimum value over all quantitatives
</span><span class="n">quants_min_nonzero</span> <span class="o">=</span> <span class="n">quants_data</span><span class="p">[</span><span class="n">quants_data</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span><span class="o">.</span><span class="nb">min</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Minimum quantitative value is {quants_data.min().min()}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"Minimum nonzero quantitative value is {quants_min_nonzero}"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Minimum quantitative value is 0.0
Minimum nonzero quantitative value is 0.4444444444444444
</code></pre></div></div>

<p>Since the minimum nonzero quantitative value is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">&lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>, we must set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>v</mi><mi>a</mi><mi>r</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>l</mi><mi>o</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">log(var) &lt; log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span> (<code class="language-plaintext highlighter-rouge">quants_min</code>) if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>a</mi><mi>r</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">var = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> in order not to interfere with monotonicity</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Columns to log transform
</span><span class="n">log_cols</span> <span class="o">=</span> <span class="n">quants_data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'YearBuilt'</span><span class="p">,</span> <span class="s">'YearRemodAdd'</span><span class="p">,</span> <span class="s">'GarageYrBlt'</span><span class="p">,</span> <span class="s">'GarageArea'</span><span class="p">,</span> <span class="s">'AvgCond'</span><span class="p">])</span>
<span class="n">log_cols</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',
       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',
       'GrLivArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',
       'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice', 'AvgQual',
       'OverallArea', 'LotRatio'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># log transform SalePrice
</span><span class="n">clean</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">log_transform</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">log_cols</span><span class="o">=</span><span class="p">[</span><span class="s">'SalePrice'</span><span class="p">])</span>
<span class="n">drop</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">log_transform</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drop</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">log_cols</span><span class="o">=</span><span class="p">[</span><span class="s">'SalePrice'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># log transform most quantitatives
</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">log_transform</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">log_cols</span><span class="o">=</span><span class="n">log_cols</span><span class="p">)</span>
<span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">log_transform</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drop_edit</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">log_cols</span><span class="o">=</span><span class="n">log_cols</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="model-selection-and-tuning">Model selection and tuning</h2>

<h3 id="create-modeling-datasets">Create modeling datasets</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set col kinds attribute of HPDataFramePlus attribute for model data method
</span><span class="n">do_col_kinds</span><span class="p">(</span><span class="n">drop</span><span class="p">)</span>
<span class="n">do_col_kinds</span><span class="p">(</span><span class="n">drop_edit</span><span class="p">)</span>
<span class="n">do_col_kinds</span><span class="p">(</span><span class="n">clean</span><span class="p">)</span>
<span class="n">do_col_kinds</span><span class="p">(</span><span class="n">clean_edit</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># model data
</span><span class="n">mclean</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean</span><span class="o">.</span><span class="n">get_model_data</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="s">'log_SalePrice'</span><span class="p">))</span>
<span class="n">mclean_edit</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">clean_edit</span><span class="o">.</span><span class="n">get_model_data</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="s">'log_SalePrice'</span><span class="p">))</span>
<span class="n">mdrop</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drop</span><span class="o">.</span><span class="n">get_model_data</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="s">'log_SalePrice'</span><span class="p">))</span>
<span class="n">mdrop_edit</span> <span class="o">=</span> <span class="n">HPDataFramePlus</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">drop_edit</span><span class="o">.</span><span class="n">get_model_data</span><span class="p">(</span><span class="n">response</span><span class="o">=</span><span class="s">'log_SalePrice'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mclean</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
MultiIndex: 2916 entries, (train, 1) to (test, 2919)
Columns: 230 entries, LotFrontage to log_SalePrice
dtypes: float64(230)
memory usage: 5.2+ MB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mclean_edit</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
MultiIndex: 2916 entries, (train, 1) to (test, 2919)
Columns: 222 entries, LotShape to log_SalePrice
dtypes: float64(222)
memory usage: 5.0+ MB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mdrop</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
MultiIndex: 2916 entries, (train, 1) to (test, 2919)
Columns: 173 entries, LotFrontage to log_SalePrice
dtypes: float64(173)
memory usage: 4.0+ MB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mdrop_edit</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
MultiIndex: 2916 entries, (train, 1) to (test, 2919)
Columns: 176 entries, LotShape to log_SalePrice
dtypes: float64(176)
memory usage: 4.0+ MB
</code></pre></div></div>

<h3 id="compare-default-models-for-baseline">Compare default models for baseline</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hpdfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">mclean</span><span class="p">,</span> <span class="n">mdrop</span><span class="p">,</span> <span class="n">mclean_edit</span><span class="p">,</span> <span class="n">mdrop_edit</span><span class="p">]</span>
<span class="n">data_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'clean'</span><span class="p">,</span> <span class="s">'drop'</span><span class="p">,</span> <span class="s">'clean_edit'</span><span class="p">,</span> <span class="s">'drop_edit'</span><span class="p">]</span>
<span class="n">response</span> <span class="o">=</span> <span class="s">'log_SalePrice'</span>
<span class="n">model_data</span> <span class="o">=</span> <span class="n">build_model_data</span><span class="p">(</span><span class="n">hpdfs</span><span class="p">,</span> <span class="n">data_names</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>
</code></pre></div></div>

<p>First we’ll look at a selection of untuned models with default parameters to get a rough idea of which ones might have better performance.</p>

<p>We’ll use root mean squared error (RMSE) for our loss function. Since we have a relatively small dataset, we’ll use cross-validation to estimate rmse for test data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fit some default regressor models
</span><span class="n">def_models</span> <span class="o">=</span> <span class="p">{</span><span class="s">'lasso'</span><span class="p">:</span> <span class="n">Lasso</span><span class="p">(),</span> 
              <span class="s">'ridge'</span><span class="p">:</span> <span class="n">Ridge</span><span class="p">(),</span>
              <span class="s">'bridge'</span><span class="p">:</span> <span class="n">BayesianRidge</span><span class="p">(),</span>
              <span class="s">'pls'</span><span class="p">:</span> <span class="n">PLSRegression</span><span class="p">(),</span> 
              <span class="s">'svr'</span><span class="p">:</span> <span class="n">SVR</span><span class="p">(),</span>
              <span class="s">'knn'</span><span class="p">:</span> <span class="n">KNeighborsRegressor</span><span class="p">(),</span>
              <span class="s">'mlp'</span><span class="p">:</span> <span class="n">MLPRegressor</span><span class="p">(),</span>
              <span class="s">'dectree'</span><span class="p">:</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
              <span class="s">'extratree'</span><span class="p">:</span> <span class="n">ExtraTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">),</span>
              <span class="s">'xgb'</span><span class="p">:</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="s">'reg:squarederror'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)}</span>


<span class="n">fit_def_models</span> <span class="o">=</span> <span class="n">fit_default_models</span><span class="p">(</span><span class="n">model_data</span><span class="p">,</span> <span class="n">def_models</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare default models 
</span><span class="n">def_comp_df</span> <span class="o">=</span> <span class="n">compare_performance</span><span class="p">(</span><span class="n">fit_def_models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">def_comp_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">(</span><span class="s">'clean'</span><span class="p">,</span> <span class="s">'cv_rmse'</span><span class="p">))</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean</th>
      <th colspan="2" halign="left">drop</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>bridge</td>
      <td>0.0950012</td>
      <td>0.115226</td>
      <td>0.0988284</td>
      <td>0.11371</td>
      <td>0.094478</td>
      <td>0.11409</td>
      <td>0.0996576</td>
      <td>0.115962</td>
    </tr>
    <tr>
      <td>1</td>
      <td>ridge</td>
      <td>0.0948572</td>
      <td>0.116246</td>
      <td>0.099311</td>
      <td>0.114194</td>
      <td>0.094225</td>
      <td>0.113706</td>
      <td>0.0998434</td>
      <td>0.116375</td>
    </tr>
    <tr>
      <td>2</td>
      <td>xgb</td>
      <td>0.0853461</td>
      <td>0.122093</td>
      <td>0.0895599</td>
      <td>0.123479</td>
      <td>0.0876669</td>
      <td>0.123595</td>
      <td>0.0889219</td>
      <td>0.126636</td>
    </tr>
    <tr>
      <td>3</td>
      <td>pls</td>
      <td>0.122064</td>
      <td>0.127405</td>
      <td>0.127452</td>
      <td>0.133998</td>
      <td>0.130416</td>
      <td>0.13708</td>
      <td>0.133912</td>
      <td>0.139404</td>
    </tr>
    <tr>
      <td>4</td>
      <td>svr</td>
      <td>0.122741</td>
      <td>0.134491</td>
      <td>0.123251</td>
      <td>0.13529</td>
      <td>0.120197</td>
      <td>0.131894</td>
      <td>0.123082</td>
      <td>0.134709</td>
    </tr>
    <tr>
      <td>5</td>
      <td>mlp</td>
      <td>0.116434</td>
      <td>0.172462</td>
      <td>0.123199</td>
      <td>0.182601</td>
      <td>0.113073</td>
      <td>0.162779</td>
      <td>0.122168</td>
      <td>0.171919</td>
    </tr>
    <tr>
      <td>6</td>
      <td>dectree</td>
      <td>2.93011e-05</td>
      <td>0.200113</td>
      <td>2.52372e-05</td>
      <td>0.205864</td>
      <td>3.15449e-05</td>
      <td>0.206949</td>
      <td>2.48969e-05</td>
      <td>0.200551</td>
    </tr>
    <tr>
      <td>7</td>
      <td>knn</td>
      <td>0.164677</td>
      <td>0.20921</td>
      <td>0.161079</td>
      <td>0.201135</td>
      <td>0.153413</td>
      <td>0.194985</td>
      <td>0.153466</td>
      <td>0.18835</td>
    </tr>
    <tr>
      <td>8</td>
      <td>extratree</td>
      <td>2.26808e-05</td>
      <td>0.211913</td>
      <td>1.40429e-05</td>
      <td>0.216413</td>
      <td>1.66016e-05</td>
      <td>0.209181</td>
      <td>1.87349e-05</td>
      <td>0.213926</td>
    </tr>
    <tr>
      <td>9</td>
      <td>lasso</td>
      <td>0.399557</td>
      <td>0.399865</td>
      <td>0.399557</td>
      <td>0.399721</td>
      <td>0.399557</td>
      <td>0.400058</td>
      <td>0.399557</td>
      <td>0.399743</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare train and cv performance for each dataset
</span><span class="n">data_palette</span> <span class="o">=</span> <span class="p">{</span><span class="s">'train_rmse'</span><span class="p">:</span> <span class="s">'cornflowerblue'</span><span class="p">,</span> <span class="s">'cv_rmse'</span><span class="p">:</span> <span class="s">'midnightblue'</span><span class="p">}</span>
<span class="n">plot_model_comp</span><span class="p">(</span><span class="n">def_comp_df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'performance'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="n">data_palette</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_53_0.png" alt="png" /></p>

<p>Unsurprisingly, all models (with the exception of <code class="language-plaintext highlighter-rouge">lasso</code> regression) had worse CV error than train error. However, for some models the difference was much greater, and these are likely overfitting. In particular, <code class="language-plaintext highlighter-rouge">dectree</code>, <code class="language-plaintext highlighter-rouge">extratree</code> had cv error roughly 5 orders of magnitude greater than train error, and <code class="language-plaintext highlighter-rouge">mlp</code>, <code class="language-plaintext highlighter-rouge">knn</code>, and <code class="language-plaintext highlighter-rouge">xgb</code> also saw significant increases.</p>

<p>The other models (<code class="language-plaintext highlighter-rouge">ridge</code>, <code class="language-plaintext highlighter-rouge">bridge</code>, <code class="language-plaintext highlighter-rouge">pls</code> and <code class="language-plaintext highlighter-rouge">svr</code>) saw slighter differences in cv and train errors, and are thus less likely overfitting.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare train and cv error across datasets
</span><span class="n">perf_palette</span> <span class="o">=</span> <span class="p">{</span><span class="s">'drop'</span><span class="p">:</span> <span class="s">'midnightblue'</span><span class="p">,</span> <span class="s">'clean'</span><span class="p">:</span> <span class="s">'forestgreen'</span><span class="p">,</span> <span class="s">'drop_edit'</span><span class="p">:</span> <span class="s">'crimson'</span><span class="p">,</span> 
           <span class="s">'clean_edit'</span><span class="p">:</span> <span class="s">'darkorange'</span><span class="p">}</span>
<span class="n">plot_model_comp</span><span class="p">(</span><span class="n">def_comp_df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'performance'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span>
                <span class="n">palette</span><span class="o">=</span><span class="n">perf_palette</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_55_0.png" alt="png" /></p>

<p>Based on cv rmse, the most promising models appear to be <code class="language-plaintext highlighter-rouge">ridge</code>, <code class="language-plaintext highlighter-rouge">bridge</code>, <code class="language-plaintext highlighter-rouge">xgb</code>, <code class="language-plaintext highlighter-rouge">svr</code>, and <code class="language-plaintext highlighter-rouge">pls</code>, which are ridge, Bayesian ridge, gradient boosted decision tree, support vector and partial least squared regressors, respectively.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop_cols</span> <span class="o">=</span> <span class="p">[(</span><span class="n">data_name</span><span class="p">,</span> <span class="s">'train_rmse'</span><span class="p">)</span> <span class="k">for</span> <span class="n">data_name</span> <span class="ow">in</span> <span class="n">data_names</span><span class="p">]</span>
<span class="n">def_comp_cv</span> <span class="o">=</span> <span class="n">def_comp_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">drop_cols</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">(</span><span class="s">'clean'</span><span class="p">,</span> <span class="s">'cv_rmse'</span><span class="p">))</span>
<span class="n">def_comp_cv</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th>clean</th>
      <th>drop</th>
      <th>clean_edit</th>
      <th>drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2</td>
      <td>bridge</td>
      <td>0.115226</td>
      <td>0.11371</td>
      <td>0.11409</td>
      <td>0.115962</td>
    </tr>
    <tr>
      <td>1</td>
      <td>ridge</td>
      <td>0.116246</td>
      <td>0.114194</td>
      <td>0.113706</td>
      <td>0.116375</td>
    </tr>
    <tr>
      <td>9</td>
      <td>xgb</td>
      <td>0.122093</td>
      <td>0.123479</td>
      <td>0.123595</td>
      <td>0.126636</td>
    </tr>
    <tr>
      <td>3</td>
      <td>pls</td>
      <td>0.127405</td>
      <td>0.133998</td>
      <td>0.13708</td>
      <td>0.139404</td>
    </tr>
    <tr>
      <td>4</td>
      <td>svr</td>
      <td>0.134491</td>
      <td>0.13529</td>
      <td>0.131894</td>
      <td>0.134709</td>
    </tr>
    <tr>
      <td>6</td>
      <td>mlp</td>
      <td>0.172462</td>
      <td>0.182601</td>
      <td>0.162779</td>
      <td>0.171919</td>
    </tr>
    <tr>
      <td>7</td>
      <td>dectree</td>
      <td>0.200113</td>
      <td>0.205864</td>
      <td>0.206949</td>
      <td>0.200551</td>
    </tr>
    <tr>
      <td>5</td>
      <td>knn</td>
      <td>0.20921</td>
      <td>0.201135</td>
      <td>0.194985</td>
      <td>0.18835</td>
    </tr>
    <tr>
      <td>8</td>
      <td>extratree</td>
      <td>0.211913</td>
      <td>0.216413</td>
      <td>0.209181</td>
      <td>0.213926</td>
    </tr>
    <tr>
      <td>0</td>
      <td>lasso</td>
      <td>0.399865</td>
      <td>0.399721</td>
      <td>0.400058</td>
      <td>0.399743</td>
    </tr>
  </tbody>
</table>
</div>

<p>Almost all models had an improvement in cv rmse when features were added, so it appears the feature engineering was warranted.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># top models by cv performance for each data set
</span><span class="n">rank_models_on_data</span><span class="p">(</span><span class="n">def_comp_cv</span><span class="p">,</span> <span class="n">model_data</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th>clean</th>
      <th>drop</th>
      <th>clean_edit</th>
      <th>drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2</td>
      <td>bridge</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>ridge</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>9</td>
      <td>xgb</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <td>3</td>
      <td>pls</td>
      <td>4</td>
      <td>4</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <td>4</td>
      <td>svr</td>
      <td>5</td>
      <td>5</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <td>6</td>
      <td>mlp</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
      <td>6</td>
    </tr>
    <tr>
      <td>7</td>
      <td>dectree</td>
      <td>7</td>
      <td>8</td>
      <td>8</td>
      <td>8</td>
    </tr>
    <tr>
      <td>5</td>
      <td>knn</td>
      <td>8</td>
      <td>7</td>
      <td>7</td>
      <td>7</td>
    </tr>
    <tr>
      <td>8</td>
      <td>extratree</td>
      <td>9</td>
      <td>9</td>
      <td>9</td>
      <td>9</td>
    </tr>
    <tr>
      <td>0</td>
      <td>lasso</td>
      <td>10</td>
      <td>10</td>
      <td>10</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
</div>

<p>The top five models were consistent across all four versions of the dataset, and were the promising models identified earlier. In order, they are <code class="language-plaintext highlighter-rouge">ridge</code>, <code class="language-plaintext highlighter-rouge">bridge</code>, <code class="language-plaintext highlighter-rouge">xgb</code>, with <code class="language-plaintext highlighter-rouge">svr</code> and <code class="language-plaintext highlighter-rouge">pls</code> tied for fourth.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># rank model performance across data sets
</span><span class="n">rank_models_across_data</span><span class="p">(</span><span class="n">def_comp_cv</span><span class="p">,</span> <span class="n">model_data</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th>clean</th>
      <th>drop</th>
      <th>clean_edit</th>
      <th>drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2</td>
      <td>bridge</td>
      <td>3</td>
      <td>1</td>
      <td>2</td>
      <td>4</td>
    </tr>
    <tr>
      <td>1</td>
      <td>ridge</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>4</td>
    </tr>
    <tr>
      <td>9</td>
      <td>xgb</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <td>3</td>
      <td>pls</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <td>4</td>
      <td>svr</td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <td>6</td>
      <td>mlp</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>7</td>
      <td>dectree</td>
      <td>1</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <td>5</td>
      <td>knn</td>
      <td>4</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>8</td>
      <td>extratree</td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <td>0</td>
      <td>lasso</td>
      <td>3</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<p>The top model, <code class="language-plaintext highlighter-rouge">ridge</code> performed best on <code class="language-plaintext highlighter-rouge">clean_edit</code> and <code class="language-plaintext highlighter-rouge">drop_edit</code>. The next best model, <code class="language-plaintext highlighter-rouge">bridge</code> performed best on <code class="language-plaintext highlighter-rouge">clean</code> and <code class="language-plaintext highlighter-rouge">clean_edit</code>. Third and fourth <code class="language-plaintext highlighter-rouge">xgb</code> and <code class="language-plaintext highlighter-rouge">pls</code> performed best on <code class="language-plaintext highlighter-rouge">clean</code> and <code class="language-plaintext highlighter-rouge">drop</code>. Finally <code class="language-plaintext highlighter-rouge">svr</code> performed best on <code class="language-plaintext highlighter-rouge">clean_edit</code> and <code class="language-plaintext highlighter-rouge">drop_edit</code>.</p>

<h3 id="tune-best-individual-models">Tune best individual models</h3>

<p>Here we’ll focus on tuning the most promising models from the <a href="#Compare-models">last section</a>. We’ll use both <code class="language-plaintext highlighter-rouge">clean_edit</code> and <code class="language-plaintext highlighter-rouge">drop_edit</code> since the top model performed best on these.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># retain top 5 models
</span><span class="n">drop_models</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lasso'</span><span class="p">,</span> <span class="s">'dectree'</span><span class="p">,</span> <span class="s">'extratree'</span><span class="p">,</span> <span class="s">'knn'</span><span class="p">,</span> <span class="s">'mlp'</span><span class="p">]</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">remove_models</span><span class="p">(</span><span class="n">fit_def_models</span><span class="p">,</span> <span class="n">drop_models</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
    <span class="c1"># drop models for clean and drop data
</span>    <span class="n">models</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'clean'</span><span class="p">)</span>
    <span class="n">models</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'drop'</span><span class="p">)</span>
    <span class="c1"># drop clean and drop data
</span>    <span class="n">model_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'clean'</span><span class="p">)</span>
    <span class="n">model_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'drop'</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">KeyError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'Promising models are {list(models["clean_edit"].keys())}'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Promising models are ['ridge', 'bridge', 'pls', 'svr', 'xgb']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># train test input output for clean_edit (y_test values are NaN)
</span><span class="n">X_ce_train</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'X_clean_edit_train'</span><span class="p">]</span>
<span class="n">X_ce_test</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'X_clean_edit_test'</span><span class="p">]</span>
<span class="n">y_ce_train</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'y_clean_edit_train'</span><span class="p">]</span>

<span class="c1"># train test input output for clean_edit (y_test values are NaN)
</span><span class="n">X_de_train</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'X_drop_edit_train'</span><span class="p">]</span>
<span class="n">X_de_test</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'X_drop_edit_test'</span><span class="p">]</span>
<span class="n">y_de_train</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'y_drop_edit_train'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="ridge-regression">Ridge regression</h4>

<p><a href="https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression">Ridge regression</a> is linear least squares with an <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">ℓ</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\ell_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> regularization term. We’ll fit default ridge regression models and then tune for comparison.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Default ridge regression models
</span><span class="n">ridge_models</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">ridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">ridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<p>Bayesian hyperparameter optimization is an efficient tuning method. We’ll optimize with respect to cv rmse</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ridge regression hyperparameters search space
</span><span class="n">ridge_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'alpha'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))}</span>

<span class="c1"># container for hyperparameter search trials and results
</span><span class="n">model_ho_results</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize hyperparameters
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">ridge_space</span><span class="p">,</span> 
                           <span class="n">est_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> 
                           <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> 
                           <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">ridge_space</span><span class="p">,</span> 
                           <span class="n">est_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> 
                           <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> 
                           <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [00:08&lt;00:00, 11.38it/s, best loss: 0.11253072830975036]
100%|██████████| 100/100 [00:07&lt;00:00, 13.32it/s, best loss: 0.11564439386901282]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># create and fit models with optimal hyperparameters
</span><span class="n">ridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                    <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">ridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                    <span class="n">Ridge</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">ridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">ridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare Ridge regression models
</span><span class="n">compare_performance</span><span class="p">(</span><span class="n">ridge_models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>ridge_def</td>
      <td>0.094225</td>
      <td>0.11256</td>
      <td>0.0998434</td>
      <td>0.115635</td>
    </tr>
    <tr>
      <td>1</td>
      <td>ridge_tuned</td>
      <td>0.0950445</td>
      <td>0.11315</td>
      <td>0.0996629</td>
      <td>0.114869</td>
    </tr>
  </tbody>
</table>
</div>

<p>The ridge regression model trained on the <code class="language-plaintext highlighter-rouge">clean_edit</code> dataset and tuned with Bayesian search had the best cv rmse. We note however that the model trained on <code class="language-plaintext highlighter-rouge">drop_edit</code> had a , which is promising (a lower train rmse might indicate overfitting).</p>

<p>Since ridge regression is just linear regression with a regularization term, it’s relatively straightfoward to interpret. We’ll rank the features of the best model their coefficient weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Top and bottom 10 features in best ridge model
</span><span class="n">plot_features</span><span class="p">(</span><span class="n">ridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">],</span> <span class="s">'ridge regression'</span><span class="p">,</span> <span class="n">X_ce_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
             <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_78_0.png" alt="png" /></p>

<p>The rankings of most positive feature weights are not too suprising. The most postively weighted feature was overall quality. We note condition variables and size variables are prominent.</p>

<p>The rankings of most negative feature weights are perhaps more surprising, in particular the presence of a basement and number of kitchens. Interestingly, several neighborhoods stand out as having a negative association with sale price. The most negatively weighted feature was the property being zoned commercial.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add tuned ridge models
</span><span class="n">models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span>
<span class="n">models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">ridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'ridge_tuned'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="bayesian-ridge-regression">Bayesian Ridge regression</h4>

<p><a href="https://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression">Bayesian ridge regression</a>
is similar to ridge regression except it uses Bayesian methods to estimate the regularization parameter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span> from the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Default Bayesian Ridge models
</span><span class="n">bridge_models</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">bridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">bridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">BayesianRidge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># bayesian ridge regression hyperparameter space
</span><span class="n">bridge_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha_1'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'alpha_1'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">9</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                <span class="s">'alpha_2'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'alpha_2'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">9</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                <span class="s">'lambda_1'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'lambda_1'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">9</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                <span class="s">'lambda_2'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'lambda_2'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">9</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize hyperparameters
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">bridge_space</span><span class="p">,</span> 
                           <span class="n">est_name</span><span class="o">=</span><span class="s">'bridge'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> 
                           <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> 
                           <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">bridge_space</span><span class="p">,</span> 
                           <span class="n">est_name</span><span class="o">=</span><span class="s">'bridge'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> 
                           <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> 
                           <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [00:37&lt;00:00,  2.67it/s, best loss: 0.11254203419476108]
100%|██████████| 100/100 [00:27&lt;00:00,  3.66it/s, best loss: 0.11576647439940951]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># add and fit models with optimal hyperparameters
</span><span class="n">bridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">BayesianRidge</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">bridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">BayesianRidge</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">bridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">bridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare Ridge regression models
</span><span class="n">compare_performance</span><span class="p">(</span><span class="n">bridge_models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>bridge_def</td>
      <td>0.094478</td>
      <td>0.113612</td>
      <td>0.0996576</td>
      <td>0.114887</td>
    </tr>
    <tr>
      <td>1</td>
      <td>bridge_tuned</td>
      <td>0.09467</td>
      <td>0.114397</td>
      <td>0.0996135</td>
      <td>0.115072</td>
    </tr>
  </tbody>
</table>
</div>

<p>As with ordinary ridge regression, the Bayesian ridge model trained on the <code class="language-plaintext highlighter-rouge">clean_edit</code> data and tuned with Bayesian search had the best cv rmse.</p>

<p>As with ridge regression, the model is straightforward to interpret.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Top and bottom 10 features in best Bayesian ridge model
</span><span class="n">plot_features</span><span class="p">(</span><span class="n">bridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">],</span> <span class="s">'Bayesian ridge regression'</span><span class="p">,</span> <span class="n">X_ce_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
             <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_90_0.png" alt="png" /></p>

<p>Feature weight rankings are nearly identical to the ridge model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add tuned bridge models
</span><span class="n">models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">bridge_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span>
<span class="n">models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">bridge_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'bridge_tuned'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="partial-least-squares">Partial Least Squares</h4>

<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cross_decomposition.PLSRegression.html">Partial least squares regression</a> stands out among the other models we’re tuning here as the only dimensional reduction method. It is <a href="https://scikit-learn.org/stable/modules/cross_decomposition.html#cross-decomposition">well-suited to multicollinearity in the input data</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Default partial least squares models
</span><span class="n">pls_models</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">pls_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">pls_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<p>The main hyperparameter of interest in partial least squared is the number of components (analogous to the number of components in principal component analysis) which is essentially the number of dimensions of the reduced dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># partial least squares hyperparameter spaces
</span><span class="n">pls_ce_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_iter'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'max_iter'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
                                                     <span class="n">high</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">10</span><span class="p">)),</span>
               <span class="s">'n_components'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'n_components'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                                        <span class="n">high</span><span class="o">=</span><span class="n">X_ce_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
                <span class="p">}</span>
<span class="n">pls_de_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_iter'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'max_iter'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
                                                     <span class="n">high</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">10</span><span class="p">)),</span>
               <span class="s">'n_components'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'n_components'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                                        <span class="n">high</span><span class="o">=</span><span class="n">X_de_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">))}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize hyperparameters
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">pls_ce_space</span><span class="p">,</span> <span class="n">est_name</span><span class="o">=</span><span class="s">'pls'</span><span class="p">,</span> 
                           <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">pls_de_space</span><span class="p">,</span> <span class="n">est_name</span><span class="o">=</span><span class="s">'pls'</span><span class="p">,</span>
                           <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                           <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [01:30&lt;00:00,  1.11it/s, best loss: 0.11628329440486904]
100%|██████████| 100/100 [01:02&lt;00:00,  1.60it/s, best loss: 0.11672287624670073]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># workaround to cast results of hyperopt param search to correct type
</span><span class="n">conv_params</span> <span class="o">=</span> <span class="p">[</span><span class="s">'max_iter'</span><span class="p">,</span> <span class="s">'n_components'</span><span class="p">]</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">convert_to_int</span><span class="p">(</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                           <span class="n">conv_params</span><span class="p">)</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">convert_to_int</span><span class="p">(</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                           <span class="n">conv_params</span><span class="p">)</span>

<span class="c1"># add and fit models with optimal hyperparameters
</span><span class="n">pls_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">PLSRegression</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">pls_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">PLSRegression</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">pls_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">pls_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># inspect pls optimal parameters
</span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"On the clean_edit data, optimal PLS parameters are: </span><span class="se">\n\t</span><span class="s"> {model_ho_results['clean_edit']['pls_tuned']['params']}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">"On the drop_edit data, optimal PLS parameters are: </span><span class="se">\n\t</span><span class="s"> {model_ho_results['drop_edit']['pls_tuned']['params']}"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>On the clean_edit data, optimal PLS parameters are: 
	 {'max_iter': 5690, 'n_components': 12}
On the drop_edit data, optimal PLS parameters are: 
	 {'max_iter': 2640, 'n_components': 16}
</code></pre></div></div>

<p>Interestingly, only a small number of components were deemed optimal! It’s worth recalling that this likely reflects a local minimum in the loss function, so the result should be taken with a grain of salt. However, it is interesting to note that such a low number of components are sufficient to get a competitive model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare Bayesian Ridge models on clean and edit datasets
</span><span class="n">compare_performance</span><span class="p">(</span><span class="n">pls_models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>pls_def</td>
      <td>0.130416</td>
      <td>0.136774</td>
      <td>0.133912</td>
      <td>0.139224</td>
    </tr>
    <tr>
      <td>1</td>
      <td>pls_tuned</td>
      <td>0.0948243</td>
      <td>0.115228</td>
      <td>0.0989862</td>
      <td>0.116016</td>
    </tr>
  </tbody>
</table>
</div>

<p>In contrast to ridge and Bayesian ridge regression, the tuned partial least squares had slightly lower cv rmse on the <code class="language-plaintext highlighter-rouge">drop_edit</code> dataset. This cv rmse is very close to that of tuned ridge and Bayesian ridge  models – it’s remarkable that only 16 components are required!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add tuned pls models
</span><span class="n">models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pls_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span>
<span class="n">models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pls_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'pls_tuned'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="support-vector-machine">Support Vector Machine</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Default support vector models
</span><span class="n">svr_models</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">svr_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">svr_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># hyperparameter space for SVR with rbf kernel
</span><span class="n">svr_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'gamma'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'gamma'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
             <span class="s">'C'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'C'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
             <span class="s">'epsilon'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'epsilon'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
            <span class="p">}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize hyperparameters
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">svr_space</span><span class="p">,</span> <span class="n">est_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">svr_space</span><span class="p">,</span> <span class="n">est_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [01:37&lt;00:00,  1.95s/it, best loss: 0.11318101455546818]
100%|██████████| 50/50 [01:32&lt;00:00,  1.84s/it, best loss: 0.11424890264814005]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># fit models with optimal hyperparameters
</span><span class="n">svr_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                        <span class="n">SVR</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">svr_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
                        <span class="n">SVR</span><span class="p">(</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">])</span>
<span class="n">svr_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">)</span>
<span class="n">svr_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare SVR model performance on clean and edit datasets
</span><span class="n">svr_comp_df</span> <span class="o">=</span> <span class="n">compare_performance</span><span class="p">(</span><span class="n">svr_models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">svr_comp_df</span>
</code></pre></div></div>

<p>As with all previous models, we’re seeing better performance on <code class="language-plaintext highlighter-rouge">drop_edit</code>. Again, a higher train rmse on <code class="language-plaintext highlighter-rouge">drop_edit</code> but a lower cv rmse is a positive sign.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add tuned svr models
</span><span class="n">models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">svr_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span>
<span class="n">models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">svr_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'svr_tuned'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="gradient-boosted-trees">Gradient boosted trees</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Default gradient boost tree models
</span><span class="n">xgb_models</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="s">'reg:squarederror'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="s">'reg:squarederror'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_def'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_def'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, gamma=0,
             importance_type='gain', learning_rate=0.1, max_delta_step=0,
             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,
             n_jobs=-1, nthread=None, objective='reg:squarederror',
             random_state=27, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
             seed=None, silent=None, subsample=1, verbosity=1)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># hyperparameter spaces
</span><span class="n">xgb_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'max_depth'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
             <span class="s">'n_estimators'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'n_estimators'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">50</span><span class="p">)),</span>
             <span class="s">'learning_rate'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'learning_rate'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
             <span class="s">'gamma'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'gamma'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
             <span class="s">'min_child_weight'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'min_child_weight'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
             <span class="s">'subsample'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'subsample'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
             <span class="s">'colsample_bytree'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bytree'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
             <span class="s">'colsample_bylevel'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bylevel'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
             <span class="s">'colsample_bynode'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bynode'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
             <span class="s">'reg_lambda'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'reg_lambda'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
             <span class="s">'reg_alpha'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'reg_alpha'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
            <span class="p">}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize hyperparameters
</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">xgb_space</span><span class="p">,</span> <span class="n">est_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span>
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">ho_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">xgb_space</span><span class="p">,</span> <span class="n">est_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span>
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [09:51&lt;00:00, 11.82s/it, best loss: 0.11487854997487522]
100%|██████████| 50/50 [08:56&lt;00:00, 10.74s/it, best loss: 0.12018590987034897]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># convert params to int
</span><span class="n">conv_params</span> <span class="o">=</span> <span class="p">[</span><span class="s">'max_depth'</span><span class="p">,</span> <span class="s">'min_child_weight'</span><span class="p">,</span> <span class="s">'n_estimators'</span><span class="p">]</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">convert_to_int</span><span class="p">(</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> <span class="n">conv_params</span><span class="p">)</span>
<span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">convert_to_int</span><span class="p">(</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> <span class="n">conv_params</span><span class="p">)</span>

<span class="c1"># add and fit models with optimal hyperparameters
</span><span class="n">fixed_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'objective'</span><span class="p">:</span> <span class="s">'reg:squarederror'</span><span class="p">,</span> <span class="s">'n_jobs'</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s">'random_state'</span><span class="p">:</span> <span class="mi">27</span><span class="p">}</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">XGBRegressor</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                        <span class="o">**</span><span class="n">fixed_params</span><span class="p">})</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">XGBRegressor</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="o">**</span><span class="n">model_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                        <span class="o">**</span><span class="n">fixed_params</span><span class="p">})</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">xgb_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare XGBoost models on clean_edit and drop_edit datasets
</span><span class="n">xgb_comp_df</span> <span class="o">=</span> <span class="n">compare_performance</span><span class="p">(</span><span class="n">xgb_models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">)</span>
<span class="n">xgb_comp_df</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>xgb_def</td>
      <td>0.0876669</td>
      <td>0.125045</td>
      <td>0.0889219</td>
      <td>0.125903</td>
    </tr>
    <tr>
      <td>1</td>
      <td>xgb_tuned</td>
      <td>0.0772716</td>
      <td>0.113871</td>
      <td>0.0795258</td>
      <td>0.117488</td>
    </tr>
  </tbody>
</table>
</div>

<p>In contrast to all previous models, the gradient boosted tree regressor had a lower cv rmse on <code class="language-plaintext highlighter-rouge">clean_edit</code>, but similarly to previous models train rmse was higher.</p>

<p>We can rank the features by importance (in this case, the number of times the feature was used to split a tree across all trees in the forest).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># top 20 feature importances of xgb model on drop_edit data
</span><span class="n">plot_xgb_features</span><span class="p">(</span><span class="n">xgb_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">],</span> <span class="n">X_de_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
                  <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_121_0.png" alt="png" /></p>

<p>On the <code class="language-plaintext highlighter-rouge">drop_edit</code> data, the top ten features for the gradient boosted trees regression model seem quite different from the top ten features of <a href="#Ridge-regressor">ridge regression</a>. Only <code class="language-plaintext highlighter-rouge">OverallQual</code> and <code class="language-plaintext highlighter-rouge">log_GrLivArea</code> appear in both, and whereas both rank <code class="language-plaintext highlighter-rouge">OverallQual</code> third, <code class="language-plaintext highlighter-rouge">ridge</code> ranks <code class="language-plaintext highlighter-rouge">log_GrLivArea</code> first while <code class="language-plaintext highlighter-rouge">xgb</code> ranks it tenth. While the top <code class="language-plaintext highlighter-rouge">ridge</code> features seemed plausible and natural, some of the top <code class="language-plaintext highlighter-rouge">xgb</code> features seem more surpising, especially the highest ranked feature <code class="language-plaintext highlighter-rouge">GarageType_Detached</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># replace default models with tuned models
</span><span class="n">models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">xgb_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span>
<span class="n">models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="n">xgb_models</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'xgb_tuned'</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="compare-tuned-models-and-save-parameters">Compare tuned models and save parameters</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare results of tuned models
</span><span class="n">tuned_comp_df</span> <span class="o">=</span> <span class="n">compare_performance</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">tuned_comp_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">(</span><span class="s">'clean_edit'</span><span class="p">,</span> <span class="s">'cv_rmse'</span><span class="p">))</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>svr_tuned</td>
      <td>0.06929</td>
      <td>0.112236</td>
      <td>0.0911838</td>
      <td>0.112445</td>
    </tr>
    <tr>
      <td>1</td>
      <td>ridge_tuned</td>
      <td>0.0950445</td>
      <td>0.113011</td>
      <td>0.0996629</td>
      <td>0.116393</td>
    </tr>
    <tr>
      <td>2</td>
      <td>bridge_tuned</td>
      <td>0.09467</td>
      <td>0.113658</td>
      <td>0.0996135</td>
      <td>0.114628</td>
    </tr>
    <tr>
      <td>3</td>
      <td>bridge</td>
      <td>0.094478</td>
      <td>0.113733</td>
      <td>0.0996576</td>
      <td>0.115385</td>
    </tr>
    <tr>
      <td>4</td>
      <td>ridge</td>
      <td>0.094225</td>
      <td>0.114597</td>
      <td>0.0998434</td>
      <td>0.11497</td>
    </tr>
    <tr>
      <td>5</td>
      <td>xgb_tuned</td>
      <td>0.0772716</td>
      <td>0.114933</td>
      <td>0.0795258</td>
      <td>0.11772</td>
    </tr>
    <tr>
      <td>6</td>
      <td>pls_tuned</td>
      <td>0.0948243</td>
      <td>0.115411</td>
      <td>0.0989862</td>
      <td>0.115752</td>
    </tr>
    <tr>
      <td>7</td>
      <td>xgb</td>
      <td>0.0876669</td>
      <td>0.123048</td>
      <td>0.0889219</td>
      <td>0.126444</td>
    </tr>
    <tr>
      <td>8</td>
      <td>svr</td>
      <td>0.120197</td>
      <td>0.131465</td>
      <td>0.123082</td>
      <td>0.134494</td>
    </tr>
    <tr>
      <td>9</td>
      <td>pls</td>
      <td>0.130416</td>
      <td>0.136702</td>
      <td>0.133912</td>
      <td>0.140016</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare tuned model train and cv performance on clean and edit datasets
</span><span class="n">plot_model_comp</span><span class="p">(</span><span class="n">tuned_comp_df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'performance'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">data_palette</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_126_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare clean and edit performance for train and cv error
</span><span class="n">plot_model_comp</span><span class="p">(</span><span class="n">tuned_comp_df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'performance'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">perf_palette</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_127_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pickle hyperopt trials and results
</span><span class="n">pickle_to_file</span><span class="p">(</span><span class="n">model_ho_results</span><span class="p">,</span> <span class="s">'../training/model_tuning_results.pkl'</span><span class="p">)</span>

<span class="c1"># pickle tuned models
</span><span class="n">pickle_to_file</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="s">'../training/tuned_models.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="ensembles">Ensembles</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># unpickle tuned models from last section
</span><span class="n">tuned_models</span> <span class="o">=</span> <span class="n">pickle_from_file</span><span class="p">(</span><span class="s">'../training/tuned_models.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="voting">Voting</h4>

<p>Voting ensembles predict a weighted average of base models.</p>

<p>We’ll use the implementation <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html"><code class="language-plaintext highlighter-rouge">sklearn.ensemble.VotingRegressor</code></a>. Unfortunately <code class="language-plaintext highlighter-rouge">sklearn.PLSRegressor</code>’s <code class="language-plaintext highlighter-rouge">predict</code> method returns arrays of size <code class="language-plaintext highlighter-rouge">(n_samples, 1)</code> rather than <code class="language-plaintext highlighter-rouge">(n_samples,)</code> like all all other models. This throws an error when passed in as an estimator to <code class="language-plaintext highlighter-rouge">cross_val_score</code> so we won’t use it as a base model. We also won’t use <code class="language-plaintext highlighter-rouge">bridge</code> since its feature weights were nearly identical to <code class="language-plaintext highlighter-rouge">ridge</code>, so in the end our voting regressor will consist of three base models: ridge, support vector and gradient boosted tree regression.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tuned_models</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dict_keys(['ridge', 'bridge', 'pls', 'svr', 'xgb', 'ridge_tuned', 'bridge_tuned', 'pls_tuned', 'svr_tuned', 'xgb_tuned'])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop_models</span> <span class="o">=</span> <span class="p">[</span><span class="s">'ridge'</span><span class="p">,</span> <span class="s">'bridge'</span><span class="p">,</span> <span class="s">'pls'</span><span class="p">,</span> <span class="s">'svr'</span><span class="p">,</span> <span class="s">'xgb'</span><span class="p">,</span> <span class="s">'bridge_tuned'</span><span class="p">,</span> 
               <span class="s">'pls_tuned'</span><span class="p">]</span>
<span class="n">base_pretuned</span> <span class="o">=</span> <span class="n">remove_models</span><span class="p">(</span><span class="n">tuned_models</span><span class="p">,</span> <span class="n">drop_models</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="default-base-and-uniform-weights">Default base and uniform weights</h5>

<p>For a baseline, we’ll look at a voting ensemble of default base models with uniform weights</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># Default models for Voting Regressor
</span><span class="n">base_def</span> <span class="o">=</span> <span class="p">[(</span><span class="s">'ridge'</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">()),</span> 
            <span class="p">(</span><span class="s">'svr'</span><span class="p">,</span> <span class="n">SVR</span><span class="p">()),</span> 
            <span class="p">(</span><span class="s">'xgb'</span><span class="p">,</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="s">'reg:squarederror'</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">))]</span>

<span class="c1"># Voting ensembles with uniform weights and untuned base models
</span><span class="n">ensembles</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">VotingRegressor</span><span class="p">(</span><span class="n">base_def</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_def'</span><span class="p">]</span> <span class="o">=</span> <span class="n">VotingRegressor</span><span class="p">(</span><span class="n">base_def</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_def'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_def'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="pretuned-base-and-uniform-weights">Pretuned base and uniform weights</h5>

<p>We also consider a voting ensemble with pretuned base models and uniform weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># Voting ensmebles with uniform weights for pretuned base models
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_uniform_pretuned'</span><span class="p">]</span> <span class="o">=</span> \
         <span class="n">VotingRegressor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_pretuned</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_uniform_pretuned'</span><span class="p">]</span> <span class="o">=</span> \
         <span class="n">VotingRegressor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_pretuned</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_uniform_pretuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_uniform_pretuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># voting ensemble hyperparameters for pretuned base
</span><span class="n">weight_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'voter1'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'voter1'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
               <span class="s">'voter2'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'voter2'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
               <span class="s">'voter3'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'voter3'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
              <span class="p">}</span>

<span class="n">voter_fixed_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_jobs'</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">}</span>


<span class="c1"># container for hyperparameter search trials and results
</span><span class="n">ens_ho_results</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize weights for voting ensemble with pretuned base
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">weight_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'voter'</span><span class="p">,</span> 
                       <span class="n">base_ests</span><span class="o">=</span><span class="n">base_pretuned</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">],</span>
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span>
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">voter_fixed_params</span><span class="p">,</span>
                       <span class="n">pretuned</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">weight_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'voter'</span><span class="p">,</span> 
                       <span class="n">base_ests</span><span class="o">=</span><span class="n">base_pretuned</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">],</span>
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span>
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">voter_fixed_params</span><span class="p">,</span>
                       <span class="n">pretuned</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [16:35&lt;00:00, 19.91s/it, best loss: 0.10821736452332247]
100%|██████████| 50/50 [12:22&lt;00:00, 14.85s/it, best loss: 0.11169063598085288]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># store and normalize weights
</span><span class="n">ce_pretuned_weights</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">de_pretuned_weights</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">ce_pretuned_weights</span> <span class="o">=</span> <span class="n">convert_and_normalize_weights</span><span class="p">(</span><span class="n">ce_pretuned_weights</span><span class="p">)</span>
<span class="n">de_pretuned_weights</span> <span class="o">=</span> <span class="n">convert_and_normalize_weights</span><span class="p">(</span><span class="n">de_pretuned_weights</span><span class="p">)</span>

<span class="c1"># add and fit voting ensembles of pretuned base estimators with tuned weights
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span> <span class="o">=</span> \
                    <span class="n">VotingRegressor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_pretuned</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> 
                                    <span class="n">weights</span><span class="o">=</span><span class="n">ce_pretuned_weights</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span> <span class="o">=</span> \
                    <span class="n">VotingRegressor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">base_pretuned</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> 
                                    <span class="n">weights</span><span class="o">=</span><span class="n">de_pretuned_weights</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_pretuned'</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">y_de_train</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="fully-tuned-voter">Fully tuned voter</h5>

<p>Finally, we’ll tune a voting regressors base model hyperparameters and voting weights simultaneously with Bayesian search.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># base hyperparameter spaces
</span><span class="n">ridge_base_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha_ridge'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'alpha_ridge'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))}</span>
<span class="n">svr_base_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'gamma_svr'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'gamma_svr'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'C_svr'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'C_svr'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'epsilon_svr'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'epsilon_svr'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))}</span>
<span class="n">xgb_base_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth_xgb'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'max_depth_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
                  <span class="s">'n_estimators_xgb'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'n_estimators_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">50</span><span class="p">)),</span>
                  <span class="s">'learning_rate_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'learning_rate_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                  <span class="s">'gamma_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'gamma_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'min_child_weight_xgb'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'min_child_weight_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
                  <span class="s">'subsample_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'subsample_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'colsample_bytree_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bytree_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'colsample_bylevel_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bylevel_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'colsample_bynode_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bynode_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'reg_lambda_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'reg_lambda_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'reg_alpha_xgb'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'reg_alpha_xgb'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                 <span class="p">}</span>

<span class="c1"># voting ensemble hyperparameters for untuned base
</span><span class="n">base_space</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">ridge_base_space</span><span class="p">,</span> <span class="o">**</span><span class="n">svr_base_space</span><span class="p">,</span> <span class="o">**</span><span class="n">xgb_base_space</span><span class="p">}</span>
<span class="n">voter_space</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">base_space</span><span class="p">,</span> <span class="o">**</span><span class="n">weight_space</span><span class="p">}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># optimize all voting ensemble hyperparameters jointly
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">voter_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'voter'</span><span class="p">,</span> 
                           <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> 
                           <span class="n">fixed_params</span><span class="o">=</span><span class="n">voter_fixed_params</span><span class="p">,</span>
                           <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">voter_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'voter'</span><span class="p">,</span> 
                           <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> 
                           <span class="n">fixed_params</span><span class="o">=</span><span class="n">voter_fixed_params</span><span class="p">,</span>
                           <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                           <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [09:15&lt;00:00, 11.11s/it, best loss: 0.11562031262896297]
100%|██████████| 50/50 [07:55&lt;00:00,  9.51s/it, best loss: 0.11927675656382479]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># add and fit fully tuned voting ensembles 
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">voter_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span>
                                     <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="n">voter_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'voter_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span>
                                     <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="stacking">Stacking</h4>

<p>Stacking ensembles fit a meta models to the predictions of base models. To avoid overfitting, one can use folds to generate base models predictions.
We’ll use the implementation <a href="http://rasbt.github.io/mlxtend/user_guide/regressor/StackingCVRegressor/"><code class="language-plaintext highlighter-rouge">mlxtend.StackingCVRegressor</code></a>. We’ll also choose our meta models from the set of base models (ridge, support vector, and gradient boosted tree regression).</p>

<h5 id="default-base-and-meta">Default base and meta</h5>

<p>For a baseline, we’ll consider stack ensembles for which both base and meta models have default parameters. We’ll use all three base models for each, and vary the meta model across the base models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add default base and meta without using features in secondary
</span><span class="n">ensembles</span> <span class="o">=</span> <span class="n">add_stacks</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s">'def'</span><span class="p">,</span> 
                       <span class="n">use_features_in_secondary</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add default base and meta using features in secondary
</span><span class="n">ensembles</span> <span class="o">=</span> <span class="n">add_stacks</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s">'def'</span><span class="p">,</span> 
                       <span class="n">use_features_in_secondary</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="pretuned-base-and-meta">Pretuned base and meta</h5>

<p>Now we’ll consider stack ensembles for which the base and meta models are already tuned. Again, we’ll use all three base models and vary the meta model across the base models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add pretuned base and meta without using features in secondary
</span><span class="n">ensembles</span> <span class="o">=</span> <span class="n">add_stacks</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">base_ests</span><span class="o">=</span><span class="n">base_pretuned</span><span class="p">,</span> 
                       <span class="n">meta_ests</span><span class="o">=</span><span class="n">base_pretuned</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s">'pretuned'</span><span class="p">,</span> 
                       <span class="n">use_features_in_secondary</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add pretuned base and meta using features in secondary
</span><span class="n">ensembles</span> <span class="o">=</span> <span class="n">add_stacks</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">base_ests</span><span class="o">=</span><span class="n">base_pretuned</span><span class="p">,</span> 
                       <span class="n">meta_ests</span><span class="o">=</span><span class="n">base_pretuned</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s">'pretuned'</span><span class="p">,</span> 
                       <span class="n">use_features_in_secondary</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="fully-tuned-stacks">Fully tuned stacks</h5>

<p>Finally, we’ll tune stack ensembles at once, that is we’ll tune both base and meta models simultaneously. As before, we’ll use all three base models and vary the meta model across the base models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># meta hyperparameter spaces
</span><span class="n">ridge_meta_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'alpha_ridge_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'alpha_ridge_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))}</span>
<span class="n">svr_meta_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'gamma_svr_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'gamma_svr_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'C_svr_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'C_svr_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'epsilon_svr_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'epsilon_svr_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">))}</span>
<span class="n">xgb_meta_space</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth_xgb_meta'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'max_depth_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
                  <span class="s">'n_estimators_xgb_meta'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'n_estimators_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">50</span><span class="p">)),</span>
                  <span class="s">'learning_rate_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'learning_rate_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                  <span class="s">'gamma_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'gamma_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">3</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'min_child_weight_xgb_meta'</span><span class="p">:</span> <span class="n">ho_scope</span><span class="o">.</span><span class="nb">int</span><span class="p">(</span><span class="n">hp</span><span class="o">.</span><span class="n">quniform</span><span class="p">(</span><span class="s">'min_child_weight_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">1</span><span class="p">)),</span>
                  <span class="s">'subsample_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'subsample_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'colsample_bytree_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bytree_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'colsample_bylevel_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bylevel_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'colsample_bynode_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="s">'colsample_bynode_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="s">'reg_lambda_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'reg_lambda_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                  <span class="s">'reg_alpha_xgb_meta'</span><span class="p">:</span> <span class="n">hp</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="s">'reg_alpha_xgb_meta'</span><span class="p">,</span> <span class="n">low</span><span class="o">=-</span><span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span>
                 <span class="p">}</span>
</code></pre></div></div>

<h6 id="ridge-regression-meta">Ridge regression meta</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ridge meta stack space
</span><span class="n">ridge_stack_space</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">ridge_meta_space</span><span class="p">,</span> <span class="o">**</span><span class="n">base_space</span><span class="p">}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># tune ridge stack without features in secondary
</span><span class="n">stack_fixed_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_jobs'</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s">'use_features_in_secondary'</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>

<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">ridge_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span>  <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">ridge_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span>  <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [1:03:53&lt;00:00, 76.67s/it, best loss: 0.11116389697149698]
100%|██████████| 50/50 [1:00:52&lt;00:00, 73.05s/it, best loss: 0.11283371442451827] 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># add and fit tuned ridge stacks without features in secondary
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>

<span class="c1"># tune ridge stack using features in secondary
</span><span class="n">stack_fixed_params</span><span class="p">[</span><span class="s">'use_features_in_secondary'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">ridge_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span>
                       <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">ridge_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span>
                       <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [16:36:46&lt;00:00, 1196.14s/it, best loss: 0.11201848643560201]    
100%|██████████| 50/50 [1:09:05&lt;00:00, 82.91s/it, best loss: 0.11459253422339011] 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">capture</span>
<span class="c1"># add and fit tuned ridge stacks using features in secondary
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_ridge_tuned_second'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h6 id="support-vector-machine-meta">Support Vector Machine meta</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># svr meta stack space
</span><span class="n">svr_stack_space</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">svr_meta_space</span><span class="p">,</span> <span class="o">**</span><span class="n">base_space</span><span class="p">}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># tune svr stack without features in secondary
</span>
<span class="n">stack_fixed_params</span><span class="p">[</span><span class="s">'use_features_in_secondary'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">svr_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">svr_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 50/50 [5:52:20&lt;00:00, 422.81s/it, best loss: 0.11151081203889647]    
100%|██████████| 50/50 [46:27&lt;00:00, 55.74s/it, best loss: 0.11466092839265946]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add and fit tuned svr stacks without features in secondary
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span>
                             <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span>
                             <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>


<span class="c1"># tune svr stack using features in secondary
</span><span class="n">stack_fixed_params</span><span class="p">[</span><span class="s">'use_features_in_secondary'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">svr_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">svr_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'svr'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add and fit tuned svr stacks using features in secondary
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_svr_tuned_second'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'ridge'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h6 id="gradient-boosted-tree-meta">Gradient Boosted Tree meta</h6>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># xgb meta stack space
</span><span class="n">xgb_stack_space</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">xgb_meta_space</span><span class="p">,</span> <span class="o">**</span><span class="n">base_space</span><span class="p">}</span>

<span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># tune xgb stack without features in secondary
</span><span class="n">stack_fixed_params</span><span class="p">[</span><span class="s">'use_features_in_secondary'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">xgb_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
        <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">xgb_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                       <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span> 
                       <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                       <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                       <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add and fit tuned xgb stacks without features in secondary
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># store trial objects for restarting training
</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
            <span class="p">{</span><span class="s">'trials'</span><span class="p">:</span> <span class="n">Trials</span><span class="p">(),</span> <span class="s">'params'</span><span class="p">:</span> <span class="bp">None</span><span class="p">}</span>

<span class="c1"># tune xgb stack with features in secondary
</span><span class="n">stack_fixed_params</span><span class="p">[</span><span class="s">'use_features_in_secondary'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">xgb_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                   <span class="n">X_train</span><span class="o">=</span><span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span> 
                   <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                   <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                   <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
<span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">ho_ens_results</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">ho_ens_cv_rmse</span><span class="p">,</span> <span class="n">space</span><span class="o">=</span><span class="n">xgb_stack_space</span><span class="p">,</span> <span class="n">ens_name</span><span class="o">=</span><span class="s">'stack'</span><span class="p">,</span> 
                   <span class="n">X_train</span><span class="o">=</span><span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span> 
                   <span class="n">fixed_params</span><span class="o">=</span><span class="n">stack_fixed_params</span><span class="p">,</span> <span class="n">pretuned</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                   <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span> <span class="n">max_evals</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                   <span class="n">trials</span><span class="o">=</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">][</span><span class="s">'trials'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># add and fit tuned xgb stacks with features in secondary
</span><span class="n">ensembles</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'clean_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_ce_train</span><span class="p">,</span> <span class="n">y_ce_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ensembles</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">stack_from_search_params</span><span class="p">(</span><span class="n">ens_ho_results</span><span class="p">[</span><span class="s">'drop_edit'</span><span class="p">][</span><span class="s">'stack_xgb_tuned_second'</span><span class="p">][</span><span class="s">'params'</span><span class="p">],</span> 
                             <span class="n">X_de_train</span><span class="p">,</span> <span class="n">y_de_train</span><span class="p">,</span> <span class="n">meta_name</span><span class="o">=</span><span class="s">'xgb'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="compare-ensembles">Compare ensembles</h5>

<p>Now we look at the performance of all our ensemble models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare results of tuned models -- warning this takes a LONG time
</span><span class="n">ens_comp_df</span> <span class="o">=</span> <span class="n">compare_performance</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">model_data</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span>
<span class="n">ens_comp_df</span> <span class="o">=</span> <span class="n">ens_comp_df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># comparison of ensembles sorted by cv rmse on clean edit dataset
</span><span class="n">ens_comp_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">(</span><span class="s">'clean_edit'</span><span class="p">,</span> <span class="s">'cv_rmse'</span><span class="p">),</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>voter_uniform_pretuned</td>
      <td>0.075474</td>
      <td>0.108401</td>
      <td>0.0865722</td>
      <td>0.110661</td>
    </tr>
    <tr>
      <td>1</td>
      <td>voter_pretuned</td>
      <td>0.075299</td>
      <td>0.1086</td>
      <td>0.0861689</td>
      <td>0.110256</td>
    </tr>
    <tr>
      <td>2</td>
      <td>stack_ridge_pretuned</td>
      <td>0.0746405</td>
      <td>0.1087</td>
      <td>0.0854078</td>
      <td>0.110722</td>
    </tr>
    <tr>
      <td>3</td>
      <td>stack_svr_pretuned</td>
      <td>0.0748075</td>
      <td>0.108715</td>
      <td>0.0861604</td>
      <td>0.110122</td>
    </tr>
    <tr>
      <td>4</td>
      <td>stack_svr_pretuned_second</td>
      <td>0.0720033</td>
      <td>0.109798</td>
      <td>0.0806914</td>
      <td>0.111473</td>
    </tr>
    <tr>
      <td>5</td>
      <td>stack_ridge_def</td>
      <td>0.0878178</td>
      <td>0.109917</td>
      <td>0.0909945</td>
      <td>0.114609</td>
    </tr>
    <tr>
      <td>6</td>
      <td>stack_ridge_tuned</td>
      <td>0.084249</td>
      <td>0.110514</td>
      <td>0.0762328</td>
      <td>0.110347</td>
    </tr>
    <tr>
      <td>7</td>
      <td>stack_ridge_pretuned_second</td>
      <td>0.0803682</td>
      <td>0.111236</td>
      <td>0.0867375</td>
      <td>0.112014</td>
    </tr>
    <tr>
      <td>8</td>
      <td>stack_ridge_def_second</td>
      <td>0.0882177</td>
      <td>0.111284</td>
      <td>0.0896656</td>
      <td>0.114543</td>
    </tr>
    <tr>
      <td>9</td>
      <td>stack_xgb_pretuned_second</td>
      <td>0.065358</td>
      <td>0.111331</td>
      <td>0.0737561</td>
      <td>0.113974</td>
    </tr>
    <tr>
      <td>10</td>
      <td>stack_svr_def</td>
      <td>0.0902256</td>
      <td>0.112275</td>
      <td>0.093318</td>
      <td>0.115215</td>
    </tr>
    <tr>
      <td>11</td>
      <td>voter_def</td>
      <td>0.092585</td>
      <td>0.112753</td>
      <td>0.0961106</td>
      <td>0.116457</td>
    </tr>
    <tr>
      <td>12</td>
      <td>stack_svr_tuned</td>
      <td>0.0946273</td>
      <td>0.112926</td>
      <td>0.0943019</td>
      <td>0.114366</td>
    </tr>
    <tr>
      <td>13</td>
      <td>stack_xgb_pretuned</td>
      <td>0.081221</td>
      <td>0.112994</td>
      <td>0.0917646</td>
      <td>0.116637</td>
    </tr>
    <tr>
      <td>14</td>
      <td>stack_xgb_def_second</td>
      <td>0.0787932</td>
      <td>0.11329</td>
      <td>0.0787003</td>
      <td>0.11728</td>
    </tr>
    <tr>
      <td>15</td>
      <td>voter_tuned</td>
      <td>0.0706802</td>
      <td>0.114352</td>
      <td>0.106915</td>
      <td>0.120561</td>
    </tr>
    <tr>
      <td>16</td>
      <td>stack_xgb_def</td>
      <td>0.0910824</td>
      <td>0.114399</td>
      <td>0.094562</td>
      <td>0.119964</td>
    </tr>
    <tr>
      <td>17</td>
      <td>stack_ridge_tuned_second</td>
      <td>0.0831083</td>
      <td>0.116366</td>
      <td>0.0842815</td>
      <td>0.120442</td>
    </tr>
    <tr>
      <td>18</td>
      <td>stack_svr_def_second</td>
      <td>0.0976675</td>
      <td>0.11676</td>
      <td>0.0987419</td>
      <td>0.120366</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># comparison of ensembles sorted by cv rmse on drop edit dataset
</span><span class="n">ens_comp_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">(</span><span class="s">'drop_edit'</span><span class="p">,</span> <span class="s">'cv_rmse'</span><span class="p">),</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr>
      <th>data</th>
      <th>model</th>
      <th colspan="2" halign="left">clean_edit</th>
      <th colspan="2" halign="left">drop_edit</th>
    </tr>
    <tr>
      <th>performance</th>
      <th></th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
      <th>train_rmse</th>
      <th>cv_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>3</td>
      <td>stack_svr_pretuned</td>
      <td>0.0748075</td>
      <td>0.108715</td>
      <td>0.0861604</td>
      <td>0.110122</td>
    </tr>
    <tr>
      <td>1</td>
      <td>voter_pretuned</td>
      <td>0.075299</td>
      <td>0.1086</td>
      <td>0.0861689</td>
      <td>0.110256</td>
    </tr>
    <tr>
      <td>6</td>
      <td>stack_ridge_tuned</td>
      <td>0.084249</td>
      <td>0.110514</td>
      <td>0.0762328</td>
      <td>0.110347</td>
    </tr>
    <tr>
      <td>0</td>
      <td>voter_uniform_pretuned</td>
      <td>0.075474</td>
      <td>0.108401</td>
      <td>0.0865722</td>
      <td>0.110661</td>
    </tr>
    <tr>
      <td>2</td>
      <td>stack_ridge_pretuned</td>
      <td>0.0746405</td>
      <td>0.1087</td>
      <td>0.0854078</td>
      <td>0.110722</td>
    </tr>
    <tr>
      <td>4</td>
      <td>stack_svr_pretuned_second</td>
      <td>0.0720033</td>
      <td>0.109798</td>
      <td>0.0806914</td>
      <td>0.111473</td>
    </tr>
    <tr>
      <td>7</td>
      <td>stack_ridge_pretuned_second</td>
      <td>0.0803682</td>
      <td>0.111236</td>
      <td>0.0867375</td>
      <td>0.112014</td>
    </tr>
    <tr>
      <td>9</td>
      <td>stack_xgb_pretuned_second</td>
      <td>0.065358</td>
      <td>0.111331</td>
      <td>0.0737561</td>
      <td>0.113974</td>
    </tr>
    <tr>
      <td>12</td>
      <td>stack_svr_tuned</td>
      <td>0.0946273</td>
      <td>0.112926</td>
      <td>0.0943019</td>
      <td>0.114366</td>
    </tr>
    <tr>
      <td>8</td>
      <td>stack_ridge_def_second</td>
      <td>0.0882177</td>
      <td>0.111284</td>
      <td>0.0896656</td>
      <td>0.114543</td>
    </tr>
    <tr>
      <td>5</td>
      <td>stack_ridge_def</td>
      <td>0.0878178</td>
      <td>0.109917</td>
      <td>0.0909945</td>
      <td>0.114609</td>
    </tr>
    <tr>
      <td>10</td>
      <td>stack_svr_def</td>
      <td>0.0902256</td>
      <td>0.112275</td>
      <td>0.093318</td>
      <td>0.115215</td>
    </tr>
    <tr>
      <td>11</td>
      <td>voter_def</td>
      <td>0.092585</td>
      <td>0.112753</td>
      <td>0.0961106</td>
      <td>0.116457</td>
    </tr>
    <tr>
      <td>13</td>
      <td>stack_xgb_pretuned</td>
      <td>0.081221</td>
      <td>0.112994</td>
      <td>0.0917646</td>
      <td>0.116637</td>
    </tr>
    <tr>
      <td>14</td>
      <td>stack_xgb_def_second</td>
      <td>0.0787932</td>
      <td>0.11329</td>
      <td>0.0787003</td>
      <td>0.11728</td>
    </tr>
    <tr>
      <td>16</td>
      <td>stack_xgb_def</td>
      <td>0.0910824</td>
      <td>0.114399</td>
      <td>0.094562</td>
      <td>0.119964</td>
    </tr>
    <tr>
      <td>18</td>
      <td>stack_svr_def_second</td>
      <td>0.0976675</td>
      <td>0.11676</td>
      <td>0.0987419</td>
      <td>0.120366</td>
    </tr>
    <tr>
      <td>17</td>
      <td>stack_ridge_tuned_second</td>
      <td>0.0831083</td>
      <td>0.116366</td>
      <td>0.0842815</td>
      <td>0.120442</td>
    </tr>
    <tr>
      <td>15</td>
      <td>voter_tuned</td>
      <td>0.0706802</td>
      <td>0.114352</td>
      <td>0.106915</td>
      <td>0.120561</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare top 10 tuned model train and cv performance on clean 
</span><span class="n">plot_model_comp</span><span class="p">(</span><span class="n">ens_comp_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'performance'</span><span class="p">,</span> 
                <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">data_palette</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_185_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compare clean and edit performance for train and cv error
</span><span class="n">plot_model_comp</span><span class="p">(</span><span class="n">ens_comp_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="s">'performance'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> 
                <span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="n">perf_palette</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/ames_house_prices/assets/images/model_186_0.png" alt="png" /></p>

<p>Overall, ensembles with pretuned base models performed better than those that were tuned all at once. Voting ensembles with pretuned bases and stack ensembles with ridge and support vector meta models were top models for both data sets.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pickle tuned parameters
</span><span class="n">pickle_to_file</span><span class="p">(</span><span class="n">ensembles</span><span class="p">,</span> <span class="s">'../training/ens_tuned_params.pkl'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="predict-and-evaluate">Predict and Evaluate</h2>

<p>To check our test prediction performance we need to submit to Kaggle. We’ll submit predictions for the top five ensemble models for both versions of the data (<code class="language-plaintext highlighter-rouge">clean_edit</code> and <code class="language-plaintext highlighter-rouge">drop_edit</code>) and report them here.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># save top 5 models from both data sets
</span><span class="n">save_top_model_predictions</span><span class="p">(</span><span class="n">ensembles</span><span class="o">=</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">ens_comp_df</span><span class="o">=</span><span class="n">ens_comp_df</span><span class="p">,</span> 
               <span class="n">data_name</span><span class="o">=</span><span class="s">'clean_edit'</span><span class="p">,</span> <span class="n">model_data</span><span class="o">=</span><span class="n">model_data</span><span class="p">,</span> 
               <span class="n">num_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s">'../submissions'</span><span class="p">)</span>

<span class="n">save_top_model_predictions</span><span class="p">(</span><span class="n">ensembles</span><span class="o">=</span><span class="n">ensembles</span><span class="p">,</span> <span class="n">ens_comp_df</span><span class="o">=</span><span class="n">ens_comp_df</span><span class="p">,</span> 
               <span class="n">data_name</span><span class="o">=</span><span class="s">'drop_edit'</span><span class="p">,</span> <span class="n">model_data</span><span class="o">=</span><span class="n">model_data</span><span class="p">,</span> 
               <span class="n">num_models</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s">'../submissions'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Enter results of Kaggle submissions
</span><span class="n">test_comp_df</span> <span class="o">=</span> <span class="n">test_comp</span><span class="p">(</span><span class="n">ens_comp_df</span><span class="p">)</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'stack_ridge_pretuned_drop_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12297</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'voter_uniform_pretuned_drop_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12307</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'stack_ridge_tuned_drop_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12132</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'voter_pretuned_drop_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12299</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'stack_svr_pretuned_drop_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12329</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'stack_svr_pretuned_second_clean_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12299</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'stack_svr_pretuned_clean_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12192</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'stack_ridge_pretuned_clean_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12203</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'voter_pretuned_clean_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12192</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'voter_uniform_pretuned_clean_edit'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.12193</span>
<span class="n">test_comp_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'test_rmse'</span><span class="p">)</span>
</code></pre></div></div>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test_rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>stack_ridge_tuned_drop_edit</td>
      <td>0.12132</td>
    </tr>
    <tr>
      <td>voter_pretuned_clean_edit</td>
      <td>0.12192</td>
    </tr>
    <tr>
      <td>stack_svr_pretuned_clean_edit</td>
      <td>0.12192</td>
    </tr>
    <tr>
      <td>voter_uniform_pretuned_clean_edit</td>
      <td>0.12193</td>
    </tr>
    <tr>
      <td>stack_ridge_pretuned_clean_edit</td>
      <td>0.12203</td>
    </tr>
    <tr>
      <td>stack_ridge_pretuned_drop_edit</td>
      <td>0.12297</td>
    </tr>
    <tr>
      <td>stack_svr_pretuned_second_clean_edit</td>
      <td>0.12299</td>
    </tr>
    <tr>
      <td>voter_pretuned_drop_edit</td>
      <td>0.12299</td>
    </tr>
    <tr>
      <td>voter_uniform_pretuned_drop_edit</td>
      <td>0.12307</td>
    </tr>
    <tr>
      <td>stack_svr_pretuned_drop_edit</td>
      <td>0.12329</td>
    </tr>
  </tbody>
</table>
</div>

<p><a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation">Per Kaggle</a>, “submissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price”. That is submission scores are</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo fence="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><msup><mo fence="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex"> \sqrt{\frac{1}{n}\sum_{i=1}^n\big(log(y_{i, pred}) - log(y_{i, actual})\big)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.1568160000000005em;vertical-align:-1.277669em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000006em;"><span class="svg-align" style="top:-5.116816em;"><span class="pstrut" style="height:5.116816em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mord"><span class="delimsizing size1">)</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.054008em;"><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em;"><span class="pstrut" style="height:5.116816em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.196816em;"><svg width="400em" height="3.196816em" viewBox="0 0 400000 3196" preserveAspectRatio="xMinYMin slice"><path d="M702 80H40000040 H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1 h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170 c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667 219 661 l218 661zM702 80H400000v40H742z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span></span></span></span></span></p>

<p>It follows that we can identify</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo fence="false">(</mo><mfrac><msub><mi>y</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub></mfrac><mo fence="false">)</mo><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">\epsilon = |log(y_{pred}) - log(y_{actual})| = |log\big(\frac{y_{pred}}{y_{actual}}\big)|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">ϵ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.988em;vertical-align:-0.8804400000000001em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804400000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="delimsizing size1">)</span></span><span class="mord">∣</span></span></span></span></span></p>

<p>with the error in this case, and thus the values in <code class="language-plaintext highlighter-rouge">test_comp_df</code> as point estimates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>ϵ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\epsilon}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">ϵ</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> for each model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># mean test_rmse
</span><span class="n">test_comp_df</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test_rmse    0.122443
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># std dev test rmse
</span><span class="n">test_comp_df</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test_rmse    0.000685
dtype: float64
</code></pre></div></div>

<p>To get a better sense of our model performances, we can consider average test error as a point estimate <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>ϵ</mi><mo>^</mo></mover><mo>=</mo><mn>0.12</mn></mrow><annotation encoding="application/x-tex"> \hat{\epsilon} = 0.12 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">ϵ</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span></span></span></span></span>. It’s unclear from the instructions (or discussion) which logarithm base was used, but assuming it’s natural log, this yields</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.88</mn><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>⪅</mo><msub><mi>y</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>⪅</mo><mn>1.13</mn><msub><mi>y</mi><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex"> 0.88 y_{actual}  \lessapprox y_{pred} \lessapprox 1.13 y_{actual} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.01166em;vertical-align:-0.25583em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span><span class="mord">8</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⪅</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.041938em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⪅</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">1</span><span class="mord">3</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>


</div>

      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', functione. {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
